<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 2.0.10">
<meta name="author" content="Por Sthefania Fernandes">
<title>Processamento Digital de Imagens</title>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700">
<style>
/* Asciidoctor default stylesheet | MIT License | https://asciidoctor.org */
/* Uncomment @import statement to use as custom stylesheet */
/*@import "https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700";*/
article,aside,details,figcaption,figure,footer,header,hgroup,main,nav,section{display:block}
audio,video{display:inline-block}
audio:not([controls]){display:none;height:0}
html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}
a{background:none}
a:focus{outline:thin dotted}
a:active,a:hover{outline:0}
h1{font-size:2em;margin:.67em 0}
abbr[title]{border-bottom:1px dotted}
b,strong{font-weight:bold}
dfn{font-style:italic}
hr{-moz-box-sizing:content-box;box-sizing:content-box;height:0}
mark{background:#ff0;color:#000}
code,kbd,pre,samp{font-family:monospace;font-size:1em}
pre{white-space:pre-wrap}
q{quotes:"\201C" "\201D" "\2018" "\2019"}
small{font-size:80%}
sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}
sup{top:-.5em}
sub{bottom:-.25em}
img{border:0}
svg:not(:root){overflow:hidden}
figure{margin:0}
fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}
legend{border:0;padding:0}
button,input,select,textarea{font-family:inherit;font-size:100%;margin:0}
button,input{line-height:normal}
button,select{text-transform:none}
button,html input[type="button"],input[type="reset"],input[type="submit"]{-webkit-appearance:button;cursor:pointer}
button[disabled],html input[disabled]{cursor:default}
input[type="checkbox"],input[type="radio"]{box-sizing:border-box;padding:0}
button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}
textarea{overflow:auto;vertical-align:top}
table{border-collapse:collapse;border-spacing:0}
*,*::before,*::after{-moz-box-sizing:border-box;-webkit-box-sizing:border-box;box-sizing:border-box}
html,body{font-size:100%}
body{background:#fff;color:rgba(0,0,0,.8);padding:0;margin:0;font-family:"Noto Serif","DejaVu Serif",serif;font-weight:400;font-style:normal;line-height:1;position:relative;cursor:auto;tab-size:4;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}
a:hover{cursor:pointer}
img,object,embed{max-width:100%;height:auto}
object,embed{height:100%}
img{-ms-interpolation-mode:bicubic}
.left{float:left!important}
.right{float:right!important}
.text-left{text-align:left!important}
.text-right{text-align:right!important}
.text-center{text-align:center!important}
.text-justify{text-align:justify!important}
.hide{display:none}
img,object,svg{display:inline-block;vertical-align:middle}
textarea{height:auto;min-height:50px}
select{width:100%}
.center{margin-left:auto;margin-right:auto}
.stretch{width:100%}
.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#7a2518;font-weight:400;margin-top:0;margin-bottom:.25em}
div,dl,dt,dd,ul,ol,li,h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6,pre,form,p,blockquote,th,td{margin:0;padding:0;direction:ltr}
a{color:#2156a5;text-decoration:underline;line-height:inherit}
a:hover,a:focus{color:#1d4b8f}
a img{border:0}
p{font-family:inherit;font-weight:400;font-size:1em;line-height:1.6;margin-bottom:1.25em;text-rendering:optimizeLegibility}
p aside{font-size:.875em;line-height:1.35;font-style:italic}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{font-family:"Open Sans","DejaVu Sans",sans-serif;font-weight:300;font-style:normal;color:#ba3925;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;line-height:1.0125em}
h1 small,h2 small,h3 small,#toctitle small,.sidebarblock>.content>.title small,h4 small,h5 small,h6 small{font-size:60%;color:#e99b8f;line-height:0}
h1{font-size:2.125em}
h2{font-size:1.6875em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.375em}
h4,h5{font-size:1.125em}
h6{font-size:1em}
hr{border:solid #dddddf;border-width:1px 0 0;clear:both;margin:1.25em 0 1.1875em;height:0}
em,i{font-style:italic;line-height:inherit}
strong,b{font-weight:bold;line-height:inherit}
small{font-size:60%;line-height:inherit}
code{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;color:rgba(0,0,0,.9)}
ul,ol,dl{font-size:1em;line-height:1.6;margin-bottom:1.25em;list-style-position:outside;font-family:inherit}
ul,ol{margin-left:1.5em}
ul li ul,ul li ol{margin-left:1.25em;margin-bottom:0;font-size:1em}
ul.square li ul,ul.circle li ul,ul.disc li ul{list-style:inherit}
ul.square{list-style-type:square}
ul.circle{list-style-type:circle}
ul.disc{list-style-type:disc}
ol li ul,ol li ol{margin-left:1.25em;margin-bottom:0}
dl dt{margin-bottom:.3125em;font-weight:bold}
dl dd{margin-bottom:1.25em}
abbr,acronym{text-transform:uppercase;font-size:90%;color:rgba(0,0,0,.8);border-bottom:1px dotted #ddd;cursor:help}
abbr{text-transform:none}
blockquote{margin:0 0 1.25em;padding:.5625em 1.25em 0 1.1875em;border-left:1px solid #ddd}
blockquote cite{display:block;font-size:.9375em;color:rgba(0,0,0,.6)}
blockquote cite::before{content:"\2014 \0020"}
blockquote cite a,blockquote cite a:visited{color:rgba(0,0,0,.6)}
blockquote,blockquote p{line-height:1.6;color:rgba(0,0,0,.85)}
@media screen and (min-width:768px){h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2}
h1{font-size:2.75em}
h2{font-size:2.3125em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.6875em}
h4{font-size:1.4375em}}
table{background:#fff;margin-bottom:1.25em;border:solid 1px #dedede}
table thead,table tfoot{background:#f7f8f7}
table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}
table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8)}
table tr.even,table tr.alt{background:#f8f8f7}
table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{display:table-cell;line-height:1.6}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2;word-spacing:-.05em}
h1 strong,h2 strong,h3 strong,#toctitle strong,.sidebarblock>.content>.title strong,h4 strong,h5 strong,h6 strong{font-weight:400}
.clearfix::before,.clearfix::after,.float-group::before,.float-group::after{content:" ";display:table}
.clearfix::after,.float-group::after{clear:both}
:not(pre):not([class^=L])>code{font-size:.9375em;font-style:normal!important;letter-spacing:0;padding:.1em .5ex;word-spacing:-.15em;background:#f7f7f8;-webkit-border-radius:4px;border-radius:4px;line-height:1.45;text-rendering:optimizeSpeed;word-wrap:break-word}
:not(pre)>code.nobreak{word-wrap:normal}
:not(pre)>code.nowrap{white-space:nowrap}
pre{color:rgba(0,0,0,.9);font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;line-height:1.45;text-rendering:optimizeSpeed}
pre code,pre pre{color:inherit;font-size:inherit;line-height:inherit}
pre>code{display:block}
pre.nowrap,pre.nowrap pre{white-space:pre;word-wrap:normal}
em em{font-style:normal}
strong strong{font-weight:400}
.keyseq{color:rgba(51,51,51,.8)}
kbd{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;display:inline-block;color:rgba(0,0,0,.8);font-size:.65em;line-height:1.45;background:#f7f7f7;border:1px solid #ccc;-webkit-border-radius:3px;border-radius:3px;-webkit-box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em white inset;box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em #fff inset;margin:0 .15em;padding:.2em .5em;vertical-align:middle;position:relative;top:-.1em;white-space:nowrap}
.keyseq kbd:first-child{margin-left:0}
.keyseq kbd:last-child{margin-right:0}
.menuseq,.menuref{color:#000}
.menuseq b:not(.caret),.menuref{font-weight:inherit}
.menuseq{word-spacing:-.02em}
.menuseq b.caret{font-size:1.25em;line-height:.8}
.menuseq i.caret{font-weight:bold;text-align:center;width:.45em}
b.button::before,b.button::after{position:relative;top:-1px;font-weight:400}
b.button::before{content:"[";padding:0 3px 0 2px}
b.button::after{content:"]";padding:0 2px 0 3px}
p a>code:hover{color:rgba(0,0,0,.9)}
#header,#content,#footnotes,#footer{width:100%;margin-left:auto;margin-right:auto;margin-top:0;margin-bottom:0;max-width:62.5em;*zoom:1;position:relative;padding-left:.9375em;padding-right:.9375em}
#header::before,#header::after,#content::before,#content::after,#footnotes::before,#footnotes::after,#footer::before,#footer::after{content:" ";display:table}
#header::after,#content::after,#footnotes::after,#footer::after{clear:both}
#content{margin-top:1.25em}
#content::before{content:none}
#header>h1:first-child{color:rgba(0,0,0,.85);margin-top:2.25rem;margin-bottom:0}
#header>h1:first-child+#toc{margin-top:8px;border-top:1px solid #dddddf}
#header>h1:only-child,body.toc2 #header>h1:nth-last-child(2){border-bottom:1px solid #dddddf;padding-bottom:8px}
#header .details{border-bottom:1px solid #dddddf;line-height:1.45;padding-top:.25em;padding-bottom:.25em;padding-left:.25em;color:rgba(0,0,0,.6);display:-ms-flexbox;display:-webkit-flex;display:flex;-ms-flex-flow:row wrap;-webkit-flex-flow:row wrap;flex-flow:row wrap}
#header .details span:first-child{margin-left:-.125em}
#header .details span.email a{color:rgba(0,0,0,.85)}
#header .details br{display:none}
#header .details br+span::before{content:"\00a0\2013\00a0"}
#header .details br+span.author::before{content:"\00a0\22c5\00a0";color:rgba(0,0,0,.85)}
#header .details br+span#revremark::before{content:"\00a0|\00a0"}
#header #revnumber{text-transform:capitalize}
#header #revnumber::after{content:"\00a0"}
#content>h1:first-child:not([class]){color:rgba(0,0,0,.85);border-bottom:1px solid #dddddf;padding-bottom:8px;margin-top:0;padding-top:1rem;margin-bottom:1.25rem}
#toc{border-bottom:1px solid #e7e7e9;padding-bottom:.5em}
#toc>ul{margin-left:.125em}
#toc ul.sectlevel0>li>a{font-style:italic}
#toc ul.sectlevel0 ul.sectlevel1{margin:.5em 0}
#toc ul{font-family:"Open Sans","DejaVu Sans",sans-serif;list-style-type:none}
#toc li{line-height:1.3334;margin-top:.3334em}
#toc a{text-decoration:none}
#toc a:active{text-decoration:underline}
#toctitle{color:#7a2518;font-size:1.2em}
@media screen and (min-width:768px){#toctitle{font-size:1.375em}
body.toc2{padding-left:15em;padding-right:0}
#toc.toc2{margin-top:0!important;background:#f8f8f7;position:fixed;width:15em;left:0;top:0;border-right:1px solid #e7e7e9;border-top-width:0!important;border-bottom-width:0!important;z-index:1000;padding:1.25em 1em;height:100%;overflow:auto}
#toc.toc2 #toctitle{margin-top:0;margin-bottom:.8rem;font-size:1.2em}
#toc.toc2>ul{font-size:.9em;margin-bottom:0}
#toc.toc2 ul ul{margin-left:0;padding-left:1em}
#toc.toc2 ul.sectlevel0 ul.sectlevel1{padding-left:0;margin-top:.5em;margin-bottom:.5em}
body.toc2.toc-right{padding-left:0;padding-right:15em}
body.toc2.toc-right #toc.toc2{border-right-width:0;border-left:1px solid #e7e7e9;left:auto;right:0}}
@media screen and (min-width:1280px){body.toc2{padding-left:20em;padding-right:0}
#toc.toc2{width:20em}
#toc.toc2 #toctitle{font-size:1.375em}
#toc.toc2>ul{font-size:.95em}
#toc.toc2 ul ul{padding-left:1.25em}
body.toc2.toc-right{padding-left:0;padding-right:20em}}
#content #toc{border-style:solid;border-width:1px;border-color:#e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;-webkit-border-radius:4px;border-radius:4px}
#content #toc>:first-child{margin-top:0}
#content #toc>:last-child{margin-bottom:0}
#footer{max-width:100%;background:rgba(0,0,0,.8);padding:1.25em}
#footer-text{color:rgba(255,255,255,.8);line-height:1.44}
#content{margin-bottom:.625em}
.sect1{padding-bottom:.625em}
@media screen and (min-width:768px){#content{margin-bottom:1.25em}
.sect1{padding-bottom:1.25em}}
.sect1:last-child{padding-bottom:0}
.sect1+.sect1{border-top:1px solid #e7e7e9}
#content h1>a.anchor,h2>a.anchor,h3>a.anchor,#toctitle>a.anchor,.sidebarblock>.content>.title>a.anchor,h4>a.anchor,h5>a.anchor,h6>a.anchor{position:absolute;z-index:1001;width:1.5ex;margin-left:-1.5ex;display:block;text-decoration:none!important;visibility:hidden;text-align:center;font-weight:400}
#content h1>a.anchor::before,h2>a.anchor::before,h3>a.anchor::before,#toctitle>a.anchor::before,.sidebarblock>.content>.title>a.anchor::before,h4>a.anchor::before,h5>a.anchor::before,h6>a.anchor::before{content:"\00A7";font-size:.85em;display:block;padding-top:.1em}
#content h1:hover>a.anchor,#content h1>a.anchor:hover,h2:hover>a.anchor,h2>a.anchor:hover,h3:hover>a.anchor,#toctitle:hover>a.anchor,.sidebarblock>.content>.title:hover>a.anchor,h3>a.anchor:hover,#toctitle>a.anchor:hover,.sidebarblock>.content>.title>a.anchor:hover,h4:hover>a.anchor,h4>a.anchor:hover,h5:hover>a.anchor,h5>a.anchor:hover,h6:hover>a.anchor,h6>a.anchor:hover{visibility:visible}
#content h1>a.link,h2>a.link,h3>a.link,#toctitle>a.link,.sidebarblock>.content>.title>a.link,h4>a.link,h5>a.link,h6>a.link{color:#ba3925;text-decoration:none}
#content h1>a.link:hover,h2>a.link:hover,h3>a.link:hover,#toctitle>a.link:hover,.sidebarblock>.content>.title>a.link:hover,h4>a.link:hover,h5>a.link:hover,h6>a.link:hover{color:#a53221}
details,.audioblock,.imageblock,.literalblock,.listingblock,.stemblock,.videoblock{margin-bottom:1.25em}
details>summary:first-of-type{cursor:pointer;display:list-item;outline:none;margin-bottom:.75em}
.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{text-rendering:optimizeLegibility;text-align:left;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem;font-style:italic}
table.tableblock.fit-content>caption.title{white-space:nowrap;width:0}
.paragraph.lead>p,#preamble>.sectionbody>[class="paragraph"]:first-of-type p{font-size:1.21875em;line-height:1.6;color:rgba(0,0,0,.85)}
table.tableblock #preamble>.sectionbody>[class="paragraph"]:first-of-type p{font-size:inherit}
.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}
.admonitionblock>table td.icon{text-align:center;width:80px}
.admonitionblock>table td.icon img{max-width:none}
.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}
.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #dddddf;color:rgba(0,0,0,.6)}
.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}
.exampleblock>.content{border-style:solid;border-width:1px;border-color:#e6e6e6;margin-bottom:1.25em;padding:1.25em;background:#fff;-webkit-border-radius:4px;border-radius:4px}
.exampleblock>.content>:first-child{margin-top:0}
.exampleblock>.content>:last-child{margin-bottom:0}
.sidebarblock{border-style:solid;border-width:1px;border-color:#dbdbd6;margin-bottom:1.25em;padding:1.25em;background:#f3f3f2;-webkit-border-radius:4px;border-radius:4px}
.sidebarblock>:first-child{margin-top:0}
.sidebarblock>:last-child{margin-bottom:0}
.sidebarblock>.content>.title{color:#7a2518;margin-top:0;text-align:center}
.exampleblock>.content>:last-child>:last-child,.exampleblock>.content .olist>ol>li:last-child>:last-child,.exampleblock>.content .ulist>ul>li:last-child>:last-child,.exampleblock>.content .qlist>ol>li:last-child>:last-child,.sidebarblock>.content>:last-child>:last-child,.sidebarblock>.content .olist>ol>li:last-child>:last-child,.sidebarblock>.content .ulist>ul>li:last-child>:last-child,.sidebarblock>.content .qlist>ol>li:last-child>:last-child{margin-bottom:0}
.literalblock pre,.listingblock>.content>pre{-webkit-border-radius:4px;border-radius:4px;word-wrap:break-word;overflow-x:auto;padding:1em;font-size:.8125em}
@media screen and (min-width:768px){.literalblock pre,.listingblock>.content>pre{font-size:.90625em}}
@media screen and (min-width:1280px){.literalblock pre,.listingblock>.content>pre{font-size:1em}}
.literalblock pre,.listingblock>.content>pre:not(.highlight),.listingblock>.content>pre[class="highlight"],.listingblock>.content>pre[class^="highlight "]{background:#f7f7f8}
.literalblock.output pre{color:#f7f7f8;background:rgba(0,0,0,.9)}
.listingblock>.content{position:relative}
.listingblock code[data-lang]::before{display:none;content:attr(data-lang);position:absolute;font-size:.75em;top:.425rem;right:.5rem;line-height:1;text-transform:uppercase;color:inherit;opacity:.5}
.listingblock:hover code[data-lang]::before{display:block}
.listingblock.terminal pre .command::before{content:attr(data-prompt);padding-right:.5em;color:inherit;opacity:.5}
.listingblock.terminal pre .command:not([data-prompt])::before{content:"$"}
.listingblock pre.highlightjs{padding:0}
.listingblock pre.highlightjs>code{padding:1em;-webkit-border-radius:4px;border-radius:4px}
.listingblock pre.prettyprint{border-width:0}
.prettyprint{background:#f7f7f8}
pre.prettyprint .linenums{line-height:1.45;margin-left:2em}
pre.prettyprint li{background:none;list-style-type:inherit;padding-left:0}
pre.prettyprint li code[data-lang]::before{opacity:1}
pre.prettyprint li:not(:first-child) code[data-lang]::before{display:none}
table.linenotable{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.linenotable td[class]{color:inherit;vertical-align:top;padding:0;line-height:inherit;white-space:normal}
table.linenotable td.code{padding-left:.75em}
table.linenotable td.linenos{border-right:1px solid currentColor;opacity:.35;padding-right:.5em}
pre.pygments .lineno{border-right:1px solid currentColor;opacity:.35;display:inline-block;margin-right:.75em}
pre.pygments .lineno::before{content:"";margin-right:-.125em}
.quoteblock{margin:0 1em 1.25em 1.5em;display:table}
.quoteblock:not(.excerpt)>.title{margin-left:-1.5em;margin-bottom:.75em}
.quoteblock blockquote,.quoteblock p{color:rgba(0,0,0,.85);font-size:1.15rem;line-height:1.75;word-spacing:.1em;letter-spacing:0;font-style:italic;text-align:justify}
.quoteblock blockquote{margin:0;padding:0;border:0}
.quoteblock blockquote::before{content:"\201c";float:left;font-size:2.75em;font-weight:bold;line-height:.6em;margin-left:-.6em;color:#7a2518;text-shadow:0 1px 2px rgba(0,0,0,.1)}
.quoteblock blockquote>.paragraph:last-child p{margin-bottom:0}
.quoteblock .attribution{margin-top:.75em;margin-right:.5ex;text-align:right}
.verseblock{margin:0 1em 1.25em}
.verseblock pre{font-family:"Open Sans","DejaVu Sans",sans;font-size:1.15rem;color:rgba(0,0,0,.85);font-weight:300;text-rendering:optimizeLegibility}
.verseblock pre strong{font-weight:400}
.verseblock .attribution{margin-top:1.25rem;margin-left:.5ex}
.quoteblock .attribution,.verseblock .attribution{font-size:.9375em;line-height:1.45;font-style:italic}
.quoteblock .attribution br,.verseblock .attribution br{display:none}
.quoteblock .attribution cite,.verseblock .attribution cite{display:block;letter-spacing:-.025em;color:rgba(0,0,0,.6)}
.quoteblock.abstract blockquote::before,.quoteblock.excerpt blockquote::before,.quoteblock .quoteblock blockquote::before{display:none}
.quoteblock.abstract blockquote,.quoteblock.abstract p,.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{line-height:1.6;word-spacing:0}
.quoteblock.abstract{margin:0 1em 1.25em;display:block}
.quoteblock.abstract>.title{margin:0 0 .375em;font-size:1.15em;text-align:center}
.quoteblock.excerpt>blockquote,.quoteblock .quoteblock{padding:0 0 .25em 1em;border-left:.25em solid #dddddf}
.quoteblock.excerpt,.quoteblock .quoteblock{margin-left:0}
.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{color:inherit;font-size:1.0625rem}
.quoteblock.excerpt .attribution,.quoteblock .quoteblock .attribution{color:inherit;text-align:left;margin-right:0}
table.tableblock{max-width:100%;border-collapse:separate}
p.tableblock:last-child{margin-bottom:0}
td.tableblock>.content>:last-child{margin-bottom:-1.25em}
td.tableblock>.content>:last-child.sidebarblock{margin-bottom:0}
table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}
table.grid-all>thead>tr>.tableblock,table.grid-all>tbody>tr>.tableblock{border-width:0 1px 1px 0}
table.grid-all>tfoot>tr>.tableblock{border-width:1px 1px 0 0}
table.grid-cols>*>tr>.tableblock{border-width:0 1px 0 0}
table.grid-rows>thead>tr>.tableblock,table.grid-rows>tbody>tr>.tableblock{border-width:0 0 1px}
table.grid-rows>tfoot>tr>.tableblock{border-width:1px 0 0}
table.grid-all>*>tr>.tableblock:last-child,table.grid-cols>*>tr>.tableblock:last-child{border-right-width:0}
table.grid-all>tbody>tr:last-child>.tableblock,table.grid-all>thead:last-child>tr>.tableblock,table.grid-rows>tbody>tr:last-child>.tableblock,table.grid-rows>thead:last-child>tr>.tableblock{border-bottom-width:0}
table.frame-all{border-width:1px}
table.frame-sides{border-width:0 1px}
table.frame-topbot,table.frame-ends{border-width:1px 0}
table.stripes-all tr,table.stripes-odd tr:nth-of-type(odd),table.stripes-even tr:nth-of-type(even),table.stripes-hover tr:hover{background:#f8f8f7}
th.halign-left,td.halign-left{text-align:left}
th.halign-right,td.halign-right{text-align:right}
th.halign-center,td.halign-center{text-align:center}
th.valign-top,td.valign-top{vertical-align:top}
th.valign-bottom,td.valign-bottom{vertical-align:bottom}
th.valign-middle,td.valign-middle{vertical-align:middle}
table thead th,table tfoot th{font-weight:bold}
tbody tr th{display:table-cell;line-height:1.6;background:#f7f8f7}
tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}
p.tableblock>code:only-child{background:none;padding:0}
p.tableblock{font-size:1em}
ol{margin-left:1.75em}
ul li ol{margin-left:1.5em}
dl dd{margin-left:1.125em}
dl dd:last-child,dl dd:last-child>:last-child{margin-bottom:0}
ol>li p,ul>li p,ul dd,ol dd,.olist .olist,.ulist .ulist,.ulist .olist,.olist .ulist{margin-bottom:.625em}
ul.checklist,ul.none,ol.none,ul.no-bullet,ol.no-bullet,ol.unnumbered,ul.unstyled,ol.unstyled{list-style-type:none}
ul.no-bullet,ol.no-bullet,ol.unnumbered{margin-left:.625em}
ul.unstyled,ol.unstyled{margin-left:0}
ul.checklist{margin-left:.625em}
ul.checklist li>p:first-child>.fa-square-o:first-child,ul.checklist li>p:first-child>.fa-check-square-o:first-child{width:1.25em;font-size:.8em;position:relative;bottom:.125em}
ul.checklist li>p:first-child>input[type="checkbox"]:first-child{margin-right:.25em}
ul.inline{display:-ms-flexbox;display:-webkit-box;display:flex;-ms-flex-flow:row wrap;-webkit-flex-flow:row wrap;flex-flow:row wrap;list-style:none;margin:0 0 .625em -1.25em}
ul.inline>li{margin-left:1.25em}
.unstyled dl dt{font-weight:400;font-style:normal}
ol.arabic{list-style-type:decimal}
ol.decimal{list-style-type:decimal-leading-zero}
ol.loweralpha{list-style-type:lower-alpha}
ol.upperalpha{list-style-type:upper-alpha}
ol.lowerroman{list-style-type:lower-roman}
ol.upperroman{list-style-type:upper-roman}
ol.lowergreek{list-style-type:lower-greek}
.hdlist>table,.colist>table{border:0;background:none}
.hdlist>table>tbody>tr,.colist>table>tbody>tr{background:none}
td.hdlist1,td.hdlist2{vertical-align:top;padding:0 .625em}
td.hdlist1{font-weight:bold;padding-bottom:1.25em}
.literalblock+.colist,.listingblock+.colist{margin-top:-.5em}
.colist td:not([class]):first-child{padding:.4em .75em 0;line-height:1;vertical-align:top}
.colist td:not([class]):first-child img{max-width:none}
.colist td:not([class]):last-child{padding:.25em 0}
.thumb,.th{line-height:0;display:inline-block;border:solid 4px #fff;-webkit-box-shadow:0 0 0 1px #ddd;box-shadow:0 0 0 1px #ddd}
.imageblock.left{margin:.25em .625em 1.25em 0}
.imageblock.right{margin:.25em 0 1.25em .625em}
.imageblock>.title{margin-bottom:0}
.imageblock.thumb,.imageblock.th{border-width:6px}
.imageblock.thumb>.title,.imageblock.th>.title{padding:0 .125em}
.image.left,.image.right{margin-top:.25em;margin-bottom:.25em;display:inline-block;line-height:0}
.image.left{margin-right:.625em}
.image.right{margin-left:.625em}
a.image{text-decoration:none;display:inline-block}
a.image object{pointer-events:none}
sup.footnote,sup.footnoteref{font-size:.875em;position:static;vertical-align:super}
sup.footnote a,sup.footnoteref a{text-decoration:none}
sup.footnote a:active,sup.footnoteref a:active{text-decoration:underline}
#footnotes{padding-top:.75em;padding-bottom:.75em;margin-bottom:.625em}
#footnotes hr{width:20%;min-width:6.25em;margin:-.25em 0 .75em;border-width:1px 0 0}
#footnotes .footnote{padding:0 .375em 0 .225em;line-height:1.3334;font-size:.875em;margin-left:1.2em;margin-bottom:.2em}
#footnotes .footnote a:first-of-type{font-weight:bold;text-decoration:none;margin-left:-1.05em}
#footnotes .footnote:last-of-type{margin-bottom:0}
#content #footnotes{margin-top:-.625em;margin-bottom:0;padding:.75em 0}
.gist .file-data>table{border:0;background:#fff;width:100%;margin-bottom:0}
.gist .file-data>table td.line-data{width:99%}
div.unbreakable{page-break-inside:avoid}
.big{font-size:larger}
.small{font-size:smaller}
.underline{text-decoration:underline}
.overline{text-decoration:overline}
.line-through{text-decoration:line-through}
.aqua{color:#00bfbf}
.aqua-background{background:#00fafa}
.black{color:#000}
.black-background{background:#000}
.blue{color:#0000bf}
.blue-background{background:#0000fa}
.fuchsia{color:#bf00bf}
.fuchsia-background{background:#fa00fa}
.gray{color:#606060}
.gray-background{background:#7d7d7d}
.green{color:#006000}
.green-background{background:#007d00}
.lime{color:#00bf00}
.lime-background{background:#00fa00}
.maroon{color:#600000}
.maroon-background{background:#7d0000}
.navy{color:#000060}
.navy-background{background:#00007d}
.olive{color:#606000}
.olive-background{background:#7d7d00}
.purple{color:#600060}
.purple-background{background:#7d007d}
.red{color:#bf0000}
.red-background{background:#fa0000}
.silver{color:#909090}
.silver-background{background:#bcbcbc}
.teal{color:#006060}
.teal-background{background:#007d7d}
.white{color:#bfbfbf}
.white-background{background:#fafafa}
.yellow{color:#bfbf00}
.yellow-background{background:#fafa00}
span.icon>.fa{cursor:default}
a span.icon>.fa{cursor:inherit}
.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}
.admonitionblock td.icon .icon-note::before{content:"\f05a";color:#19407c}
.admonitionblock td.icon .icon-tip::before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}
.admonitionblock td.icon .icon-warning::before{content:"\f071";color:#bf6900}
.admonitionblock td.icon .icon-caution::before{content:"\f06d";color:#bf3400}
.admonitionblock td.icon .icon-important::before{content:"\f06a";color:#bf0000}
.conum[data-value]{display:inline-block;color:#fff!important;background:rgba(0,0,0,.8);-webkit-border-radius:100px;border-radius:100px;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]::after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}
dt,th.tableblock,td.content,div.footnote{text-rendering:optimizeLegibility}
h1,h2,p,td.content,span.alt{letter-spacing:-.01em}
p strong,td.content strong,div.footnote strong{letter-spacing:-.005em}
p,blockquote,dt,td.content,span.alt{font-size:1.0625rem}
p{margin-bottom:1.25rem}
.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock{font-size:1em}
.exampleblock>.content{background:#fffef7;border-color:#e0e0dc;-webkit-box-shadow:0 1px 4px #e0e0dc;box-shadow:0 1px 4px #e0e0dc}
.print-only{display:none!important}
@page{margin:1.25cm .75cm}
@media print{*{-webkit-box-shadow:none!important;box-shadow:none!important;text-shadow:none!important}
html{font-size:80%}
a{color:inherit!important;text-decoration:underline!important}
a.bare,a[href^="#"],a[href^="mailto:"]{text-decoration:none!important}
a[href^="http:"]:not(.bare)::after,a[href^="https:"]:not(.bare)::after{content:"(" attr(href) ")";display:inline-block;font-size:.875em;padding-left:.25em}
abbr[title]::after{content:" (" attr(title) ")"}
pre,blockquote,tr,img,object,svg{page-break-inside:avoid}
thead{display:table-header-group}
svg{max-width:100%}
p,blockquote,dt,td.content{font-size:1em;orphans:3;widows:3}
h2,h3,#toctitle,.sidebarblock>.content>.title{page-break-after:avoid}
#toc,.sidebarblock,.exampleblock>.content{background:none!important}
#toc{border-bottom:1px solid #dddddf!important;padding-bottom:0!important}
body.book #header{text-align:center}
body.book #header>h1:first-child{border:0!important;margin:2.5em 0 1em}
body.book #header .details{border:0!important;display:block;padding:0!important}
body.book #header .details span:first-child{margin-left:0!important}
body.book #header .details br{display:block}
body.book #header .details br+span::before{content:none!important}
body.book #toc{border:0!important;text-align:left!important;padding:0!important;margin:0!important}
body.book #toc,body.book #preamble,body.book h1.sect0,body.book .sect1>h2{page-break-before:always}
.listingblock code[data-lang]::before{display:block}
#footer{padding:0 .9375em}
.hide-on-print{display:none!important}
.print-only{display:block!important}
.hide-for-print{display:none!important}
.show-for-print{display:inherit!important}}
@media print,amzn-kf8{#header>h1:first-child{margin-top:1.25rem}
.sect1{padding:0!important}
.sect1+.sect1{border:0}
#footer{background:none}
#footer-text{color:rgba(0,0,0,.6);font-size:.9em}}
@media amzn-kf8{#header,#content,#footnotes,#footer{padding:0}}
</style>
</head>
<body class="article toc2 toc-left">
<div id="header">
<h1>Processamento Digital de Imagens</h1>
<div class="details">
<span id="author" class="author">Por Sthefania Fernandes</span><br>
<span id="email" class="email"><a href="mailto:sthefaniafernandes03@gmail.com">sthefaniafernandes03@gmail.com</a></span><br>
<span id="revdate">graduanda em Engenharia Mecatrônica pela UFRN</span>
</div>
<div id="toc" class="toc2">
<div id="toctitle">Sumário</div>
<ul class="sectlevel1">
<li><a href="#_introdução">Introdução</a></li>
<li><a href="#_1_manipulando_pixels_de_uma_imagem">1 Manipulando pixels de uma imagem</a>
<ul class="sectlevel2">
<li><a href="#_1_1_negativo_de_uma_região">1.1 Negativo de uma região</a></li>
<li><a href="#_1_2_troca_de_quadrantes">1.2 Troca de Quadrantes</a></li>
</ul>
</li>
<li><a href="#_2_serialização_de_dados_em_ponto_flutuante_via_filestorage">2 Serialização de dados em ponto flutuante via FileStorage</a>
<ul class="sectlevel2">
<li><a href="#_2_1_imagem_yml_e_png">2.1 Imagem YML e PNG</a></li>
</ul>
</li>
<li><a href="#_3_decomposição_de_imagens_em_planos_de_bits">3 Decomposição de imagens em planos de bits</a>
<ul class="sectlevel2">
<li><a href="#_3_1_esteganografia">3.1 Esteganografia</a></li>
</ul>
</li>
<li><a href="#_4_preenchendo_regiões">4 Preenchendo regiões</a>
<ul class="sectlevel2">
<li><a href="#_4_1_identificando_bolhas_com_ou_sem_buracos">4.1 Identificando bolhas com ou sem buracos</a></li>
</ul>
</li>
<li><a href="#_5_manipulação_de_histogramas">5 Manipulação de histogramas</a>
<ul class="sectlevel2">
<li><a href="#_5_1_equalizar_imagem_cinza">5.1 Equalizar imagem cinza</a></li>
<li><a href="#_5_2_detecção_de_movimento">5.2 Detecção de movimento</a></li>
</ul>
</li>
<li><a href="#_6_filtragem_no_domínio_espacial_i">6 Filtragem no domínio espacial I</a>
<ul class="sectlevel2">
<li><a href="#_6_1_laplaciano_do_gaussiano_de_um_vídeo">6.1 Laplaciano do gaussiano de um vídeo</a></li>
</ul>
</li>
<li><a href="#_7_filtragem_no_domínio_da_frequência">7 Filtragem no domínio da frequência</a>
<ul class="sectlevel2">
<li><a href="#_7_1_a_transformada_de_fourier">7.1 A Transformada de Fourier</a></li>
<li><a href="#_7_2_filtro_homomórfico">7.2 Filtro homomórfico</a></li>
</ul>
</li>
<li><a href="#_8_segmentação_de_imagens">8 Segmentação de imagens</a>
<ul class="sectlevel2">
<li><a href="#_8_1_pontilhismo_com_algoritmo_de_canny">8.1 Pontilhismo com algoritmo de Canny</a></li>
</ul>
</li>
<li><a href="#_projeto_final">Projeto Final</a>
<ul class="sectlevel2">
<li><a href="#_detector_de_cor_de_uma_região_de_interesse_em_tempo_real">Detector de Cor de uma Região de Interesse em Tempo Real</a></li>
<li><a href="#_referências">Referências</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div id="content">
<div class="sect1">
<h2 id="_introdução">Introdução</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Este site tem por objetivo documentar a solução dos exercícios da disciplina Processamento Digital de Imagens (DCA0445) ministrada pelo professor Agostinho Brito Jr. e disponível em <a href="https://agostinhobritojr.github.io/tutorial/pdi/" class="bare">https://agostinhobritojr.github.io/tutorial/pdi/</a>.</p>
</div>
<div class="paragraph">
<p>Todos os exercícios foram desenvolvidos usando a API C++ do OpenCV — <a href="https://opencv.org/" class="bare">https://opencv.org/</a>  — e foram testados em um ambiente executando o sistema operacional Linux (Ubuntu 20.04.6).</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_1_manipulando_pixels_de_uma_imagem">1 Manipulando pixels de uma imagem</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_1_1_negativo_de_uma_região">1.1 Negativo de uma região</h3>
<div class="paragraph">
<p>Utilizando o programa <a href="https://agostinhobritojr.github.io/tutorial/pdi/exemplos/pixels.cpp">exemplos/pixels.cpp</a> como referência, foi implementado o programa regions.cpp.</p>
</div>
<div class="paragraph">
<p>Esse programa irá solicitar ao usuário as coordenadas de dois pontos (P1 e P2), os quais devem localizar-se dentro do limites de tamanho da imagem. Essa região, definida pelos pontos P1 e P2, será exibida com o negativo da imagem utilizada pelo programa.</p>
</div>
<div class="paragraph">
<p>O algoritmo desenvolvido pode ser visualizado abaixo:</p>
</div>
<div class="listingblock">
<div class="title">Código 1: regions.cpp</div>
<div class="content">
<pre class="highlight"><code class="language-cpp" data-lang="cpp">#include &lt;iostream&gt;
#include &lt;opencv2/opencv.hpp&gt;

/*
Essa função foi feita para definir o funcionamento correto do for que tornará a imagem negativa. Afinal ele percorre do menor valor para o maior, incrementando a cada iteração, então é preciso garantir que ele inicie a contagem da menor coordenada para maior.
*/
void troca_val(int *a, int *b){

    int aux=0;

    if ((*a)&gt;(*b)){
        aux=*a;
        *a=*b;
        *b=aux;
    }
    else
        return;
}

int main (){

    cv::Mat image;
    cv::Vec2i p1;
    cv::Vec2i p2;

    image = cv::imread("biel.png", cv::IMREAD_GRAYSCALE);
    if(!image.data)
        std::cout &lt;&lt; "A imagem nao abriu" &lt;&lt; std::endl;

    cv::namedWindow("Recorte negativo", cv::WINDOW_AUTOSIZE);

    std:: cout &lt;&lt; "O tamanho da imagem é: " &lt;&lt; image.rows &lt;&lt; "x"&lt;&lt; image.cols &lt;&lt; std:: endl;
    std:: cout &lt;&lt; "Insira 2 pontos dentro do limite." &lt;&lt; std:: endl;

    /*
    o do-while é utilizado para impedir que se insira uma coordenada fora do tamanho da imagem
    */

    do {
        std::cout &lt;&lt; "Insira a coordenada x do 1º ponto:" &lt;&lt; std:: endl;
        std::cin &gt;&gt; p1[0];
    } while (p1[0]&gt;=image.rows);

    do {
        std::cout &lt;&lt; "Insira a coordenada y do 1º ponto:" &lt;&lt; std:: endl;
        std::cin &gt;&gt; p1[1];
    } while (p1[1]&gt;=image.cols);

    do {
        std::cout &lt;&lt; "Insira a coordenada x do 2º ponto:" &lt;&lt; std:: endl;
        std::cin &gt;&gt; p2[0];
    } while (p2[0]&gt;=image.rows);

    do {
        std::cout &lt;&lt; "Insira a coordenada y do 2º ponto:" &lt;&lt; std:: endl;
        std::cin &gt;&gt; p2[1];
    } while (p2[1]&gt;=image.cols);

    /*
    se a coordenada x1 e x2  ou y1 e y2 forem iguais a condição do for não é atendida e a imagem  não ficará negativa, então se alguém preencher dessa forma o programa será encerrado com aviso de erro.
    */

    if (p1[0]==p2[0]|| p1[1]==p2[1]){
        std:: cout&lt;&lt; "Erro: coordenadas inválidas. x1 deve ser diferente de x2, y1 deve ser diferente de y2." &lt;&lt; std:: endl;
        return 0;
    }

    troca_val(&amp;p1[0],&amp;p2[0]);
    troca_val(&amp;p1[1],&amp;p2[1]);

    for(int i=p1[0]; i&lt;p2[0]; i++){
        for(int j=p1[1]; j&lt;p2[1]; j++){
            image.at&lt;uchar&gt;(i,j)= 255 - image.at&lt;uchar&gt;(i,j);
        }
    }

    cv::imshow("Recorte negativo", image);
    cv::waitKey();

    return 0;
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>A parte principal desse código é definir o negativo da imagem. Isso é feito subtraindo de 255 (equivalente a cor branca em uma imagem) o valor do pixel que você quer deixar negativo. Aqui os pixels que se tornarão negativos são os definidos pelos 2 pontos inseridos pelo usuário e estes são usados como inicio e fim do laço que realiza a alteração da imagem.</p>
</div>
<div class="listingblock">
<div class="title">Código 2: Negativo de uma imagem</div>
<div class="content">
<pre class="highlight"><code class="language-cpp" data-lang="cpp">for(int i=p1[0]; i&lt;p2[0]; i++){
        for(int j=p1[1]; j&lt;p2[1]; j++){
            image.at&lt;uchar&gt;(i,j)= 255 - image.at&lt;uchar&gt;(i,j);
        }
    }</code></pre>
</div>
</div>
<div class="paragraph">
<p>A imagem utilizada nesse código é a mostrada abaixo:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="figuras/biel.png" alt="biel">
</div>
<div class="title">Figure 1. Imagem original</div>
</div>
<div class="paragraph">
<p>A saída do programa será uma imagem com uma parte negativa definida pelos pontos inseridos pelo usuário. A imagem original não será alterada e ao pressionar uma tecla qualquer do teclado a imagem negativa será fechada e não será salva.</p>
</div>
<div class="paragraph">
<p>Abaixo temos duas imagens obtidas com esse programa. A primeira utiliza os pontos (50,70)(160,30) e a segunda (50,100)(200,200).</p>
</div>
<div class="imageblock">
<div class="content">
<img src="figuras/negativos.png" alt="negativos" width="500" height="500">
</div>
<div class="title">Figure 2. Resultados do algoritmo</div>
</div>
</div>
<div class="sect2">
<h3 id="_1_2_troca_de_quadrantes">1.2 Troca de Quadrantes</h3>
<div class="paragraph">
<p>Por meio do programa <a href="https://agostinhobritojr.github.io/tutorial/pdi/exemplos/pixels.cpp">exemplos/pixels.cpp</a>, foi implementado um programa que troca quatro quadrantes de uma imagem.</p>
</div>
<div class="paragraph">
<p>No código foi utilizada a função <a href="https://docs.opencv.org/3.4/d2/d44/classcv_1_1Rect__.html">rect</a> do OpenCV para extrair regiões de uma imagem. Cada região extraída foi salva em uma nova matriz (Q1, Q2, Q3,e Q4). Utilizando a função copyTo os recortes salvos foram inseridos na matriz trocaquadrante em posições diferentes da imagem original.</p>
</div>
<div class="paragraph">
<p>O algoritmo desenvolvido pode ser visualizado abaixo:</p>
</div>
<div class="listingblock">
<div class="title">Código 3: trocaregioes.cpp</div>
<div class="content">
<pre class="highlight"><code class="language-cpp" data-lang="cpp">#include &lt;iostream&gt;
#include &lt;opencv2/opencv.hpp&gt;

int main (){
    /*Definindo imagem original*/
    cv::Mat image;
    /*Definindo imagem com os quadrantes mudados.
      Ela terá o mesmo número de linhas e colunas da imagem
      original e o mesmo tipo*/

    image = cv::imread("biel.png", cv::IMREAD_GRAYSCALE);

    if(!image.data)
        std::cout &lt;&lt; "A imagem nao abriu" &lt;&lt; std::endl;

    cv::namedWindow("Imagem original", cv::WINDOW_AUTOSIZE);
    cv::imshow("Imagem original", image);
    cv::waitKey();

    cv::Mat trocaquadrante(image.rows, image.cols, image.type());

    /*quadrante superior esquerdo*/
    cv::Mat Q1 = image(cv::Rect(0, 0, image.rows/2, image.cols/2));
    /*quadrante inferior esquerdo*/
    cv::Mat Q2 = image(cv::Rect(0, image.cols/2, image.rows/2, image.cols/2));
    /*quadrante superior direito*/
    cv::Mat Q3 = image(cv::Rect(image.rows/2, 0, image.rows/2, image.cols/2));
    /*quadrante inferior direito*/
    cv::Mat Q4 = image(cv::Rect(image.rows/2, image.cols/2, image.rows/2, image.cols/2));

    Q4.copyTo(trocaquadrante(cv::Rect(0,0,image.rows/2,image.cols/2)));
    Q3.copyTo(trocaquadrante(cv::Rect(0,image.cols/2,image.rows/2,image.cols/2)));
    Q2.copyTo(trocaquadrante(cv::Rect(image.rows/2,0,image.rows/2,image.cols/2)));
    Q1.copyTo(trocaquadrante(cv::Rect(image.rows/2,image.cols/2,image.rows/2,image.cols/2)));


    cv::namedWindow("Imagem trocada", cv::WINDOW_AUTOSIZE);
    cv::imshow("Imagem trocada", trocaquadrante);
    cv::waitKey();

    return 0;
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Como resultado do programa, obtivemos as imagens abaixo:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="figuras/trocarregioes.png" alt="trocarregioes" width="500" height="500">
</div>
<div class="title">Figure 3. Imagem original e imagem com quadrantes trocados</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_2_serialização_de_dados_em_ponto_flutuante_via_filestorage">2 Serialização de dados em ponto flutuante via FileStorage</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_2_1_imagem_yml_e_png">2.1 Imagem YML e PNG</h3>
<div class="paragraph">
<p>Utilizando o programa <a href="https://agostinhobritojr.github.io/tutorial/pdi/exemplos/filestorage.cpp">filestorage.cpp</a> como base, foi criado um programa que gera uma imagem de dimensões 256x256 pixels contendo uma senóide de 4 períodos com amplitude de 127 desenhada na horizontal. Para isso, a variável global PERIODOS recebeu o valor 4.</p>
</div>
<div class="paragraph">
<p>Definida a imagem, esta foi gravada no formato PNG e no formato YML. Em seguida foi extraída uma linha de cada imagem gravada para comparar os arquivos os valores do pixels gerados. Isso feito, foram criados dois arquivos txt para guardar os valores lidos de cada formato da imagem da senóide.</p>
</div>
<div class="paragraph">
<p>O algoritmo desenvolvido pode ser visualizado abaixo:</p>
</div>
<div class="listingblock">
<div class="title">Código 4: senoide.cpp</div>
<div class="content">
<pre class="highlight"><code class="language-cpp" data-lang="cpp">#include &lt;iostream&gt;
#include &lt;opencv2/opencv.hpp&gt;
#include &lt;sstream&gt;
#include &lt;string&gt;

int SIDE = 256;
int PERIODOS = 4;

int main(int argc, char** argv) {
    std::stringstream ss_img, ss_yml;
    cv::Mat image;

    ss_yml &lt;&lt; "senoide-" &lt;&lt; SIDE &lt;&lt; ".yml";
    image = cv::Mat::zeros(SIDE, SIDE, CV_32FC1);

    cv::FileStorage fs(ss_yml.str(), cv::FileStorage::WRITE);

    for (int i = 0; i &lt; SIDE; i++) {
      for (int j = 0; j &lt; SIDE; j++) {
        image.at&lt;float&gt;(i, j) = 127 * sin(2 * M_PI * PERIODOS * j / SIDE) + 128;
      }
    }
    /*arquivo txt da imagem yml, será coletada uma linha para comparação com png*/
    std::ofstream Fileyml("img_yml.txt");

    if (!Fileyml.is_open()){
        std::cout &lt;&lt; "Erro ao criar o arquivo .txt" &lt;&lt; std::endl;
        return -1;
    }
    for (int i = 0; i &lt; image.rows; i++)
    {
        float pixels = image.at&lt;float&gt;(i);
        Fileyml &lt;&lt; pixels &lt;&lt; " ";
    }
    Fileyml.close();

    fs &lt;&lt; "mat" &lt;&lt; image;
    fs.release();

    cv::normalize(image, image, 0, 255, cv::NORM_MINMAX);
    image.convertTo(image, CV_8U);
    ss_img &lt;&lt; "senoide-" &lt;&lt; SIDE &lt;&lt; ".png";
    cv::imwrite(ss_img.str(), image);

    fs.open(ss_yml.str(), cv::FileStorage::READ);
    fs["mat"] &gt;&gt; image;

    cv::normalize(image, image, 0, 255, cv::NORM_MINMAX);
    image.convertTo(image, CV_8U);

    /*arquivo txt da imagem png, será coletada uma linha para comparação com yml*/
    std::ofstream Filepng("img_png.txt");

    if (!Filepng.is_open()){
            std::cout &lt;&lt; "Erro ao criar o arquivo .txt" &lt;&lt; std::endl;
            return -1;
        }
        for (int i = 0; i &lt; image.rows; i++)
        {
            float pixels = image.at&lt;uchar&gt;(i);
            Filepng &lt;&lt; pixels &lt;&lt; " ";

        }
        Filepng.close();

    cv::imshow("image", image);
    cv::waitKey();

    return 0;
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Como resultado, foi gerada a seguinte imagem png da senóide.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="figuras/senoide-256.png" alt="senoide 256" width="300" height="300">
</div>
<div class="title">Figure 4. Senóide gerada pelo programa</div>
</div>
<div class="paragraph">
<p>O arquivo txt de uma linha da imagem em .png pode visto abaixo.</p>
</div>
<div class="listingblock">
<div class="title">img_png.txt</div>
<div class="content">
<pre>128 140 152 165 176 188 198 208 218 226 234 240 245 250 253 254 255 254 253 250 245 240 234 226 218 208 198 188 176 165 152 140 128 115 103 90 79 67 57 47 37 29 21 15 10 5 2 1 0 1 2 5 10 15 21 29 37 47 57 67 79 90 103 115 128 140 152 165 176 188 198 208 218 226 234 240 245 250 253 254 255 254 253 250 245 240 234 226 218 208 198 188 176 165 152 140 128 115 103 90 79 67 57 47 37 29 21 15 10 5 2 1 0 1 2 5 10 15 21 29 37 47 57 67 79 90 103 115 128 140 152 165 176 188 198 208 218 226 234 240 245 250 253 254 255 254 253 250 245 240 234 226 218 208 198 188 176 165 152 140 128 115 103 90 79 67 57 47 37 29 21 15 10 5 2 1 0 1 2 5 10 15 21 29 37 47 57 67 79 90 103 115 128 140 152 165 176 188 198 208 218 226 234 240 245 250 253 254 255 254 253 250 245 240 234 226 218 208 198 188 176 165 152 140 128 115 103 90 79 67 57 47 37 29 21 15 10 5 2 1 0 1 2 5 10 15 21 29 37 47 57 67 79 90 103 115</pre>
</div>
</div>
<div class="paragraph">
<p>Já arquivo txt de uma linha da imagem em .yml pode visto abaixo.</p>
</div>
<div class="listingblock">
<div class="title">img_yml.txt</div>
<div class="content">
<pre>128 140.448 152.776 164.866 176.601 187.867 198.557 208.568 217.803 226.172 233.597 240.004 245.333 249.531 252.56 254.388 255 254.388 252.56 249.531 245.333 240.004 233.597 226.172 217.803 208.568 198.557 187.867 176.601 164.866 152.776 140.448 128 115.552 103.224 91.1338 79.3992 68.1326 57.4426 47.4321 38.1974 29.8277 22.4034 15.996 10.6673 6.46858 3.44027 1.61154 1 1.61154 3.44027 6.46858 10.6673 15.996 22.4034 29.8277 38.1974 47.4321 57.4426 68.1326 79.3992 91.1338 103.224 115.552 128 140.448 152.776 164.866 176.601 187.867 198.557 208.568 217.803 226.172 233.597 240.004 245.333 249.531 252.56 254.388 255 254.388 252.56 249.531 245.333 240.004 233.597 226.172 217.803 208.568 198.557 187.867 176.601 164.866 152.776 140.448 128 115.552 103.224 91.1338 79.3992 68.1326 57.4426 47.4321 38.1974 29.8277 22.4034 15.996 10.6673 6.46858 3.44027 1.61154 1 1.61154 3.44027 6.46858 10.6673 15.996 22.4034 29.8277 38.1974 47.4321 57.4426 68.1326 79.3992 91.1338 103.224 115.552 128 140.448 152.776 164.866 176.601 187.867 198.557 208.568 217.803 226.172 233.597 240.004 245.333 249.531 252.56 254.388 255 254.388 252.56 249.531 245.333 240.004 233.597 226.172 217.803 208.568 198.557 187.867 176.601 164.866 152.776 140.448 128 115.552 103.224 91.1338 79.3992 68.1326 57.4426 47.4321 38.1974 29.8277 22.4034 15.996 10.6673 6.46858 3.44027 1.61154 1 1.61154 3.44027 6.46858 10.6673 15.996 22.4034 29.8277 38.1974 47.4321 57.4426 68.1326 79.3992 91.1338 103.224 115.552 128 140.448 152.776 164.866 176.601 187.867 198.557 208.568 217.803 226.172 233.597 240.004 245.333 249.531 252.56 254.388 255 254.388 252.56 249.531 245.333 240.004 233.597 226.172 217.803 208.568 198.557 187.867 176.601 164.866 152.776 140.448 128 115.552 103.224 91.1338 79.3992 68.1326 57.4426 47.4321 38.1974 29.8277 22.4034 15.996 10.6673 6.46858 3.44027 1.61154 1 1.61154 3.44027 6.46858 10.6673 15.996 22.4034 29.8277 38.1974 47.4321 57.4426 68.1326 79.3992 91.1338 103.224 115.552</pre>
</div>
</div>
<div class="paragraph">
<p>Ao comparar as duas linhas observou-se uma pequena diferença entre os valores obtidos. Como pode ser visto na Figura abaixo, a maior diferença entre os valores dos pixels foi de 1,.5</p>
</div>
<div class="imageblock">
<div class="content">
<img src="figuras/pngxyml.png" alt="pngxyml" width="600" height="600">
</div>
<div class="title">Figure 5. Comparação entre png e yml</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_3_decomposição_de_imagens_em_planos_de_bits">3 Decomposição de imagens em planos de bits</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_3_1_esteganografia">3.1 Esteganografia</h3>
<div class="paragraph">
<p>Utilizando o programa <a href="https://agostinhobritojr.github.io/tutorial/pdi/exemplos/esteg-encode.cpp">esteg-encode.cpp</a> como referência para esteganografia, foi feito um programa que recupere uma imagem codificada de uma imagem resultante de esteganografia.</p>
</div>
<div class="paragraph">
<p>Para isso, os bits da imagem portadora foram alterados de forma que os menos significativos dos pixels da imagem fornecida irão compor os bits mais significativos dos pixels da imagem recuperada.</p>
</div>
<div class="paragraph">
<p>O algoritmo desenvolvido pode ser visualizado abaixo:</p>
</div>
<div class="listingblock">
<div class="title">Código 5: decodificaimg.cpp</div>
<div class="content">
<pre class="highlight"><code class="language-cpp" data-lang="cpp">#include &lt;iostream&gt;
#include &lt;opencv2/opencv.hpp&gt;

int main(int argc, char**argv) {
  cv::Mat imagemPortadora, imagemFinal;
  cv::Vec3b valPortadora;
  int nbits = 3;

  imagemPortadora = cv::imread(argv[1], cv::IMREAD_COLOR);

  if (imagemPortadora.empty()) {
    std::cout &lt;&lt; "imagem nao carregou corretamente" &lt;&lt; std::endl;
    return (-1);
  }

  imagemFinal = imagemPortadora.clone();

  for (int i = 0; i &lt; imagemPortadora.rows; i++) {
    for (int j = 0; j &lt; imagemPortadora.cols; j++) {
      valPortadora = imagemPortadora.at&lt;cv::Vec3b&gt;(i, j);

    /*os bits menos significativos dos pixels da imagem fornecida irão compor
    os bits mais significativos dos pixels da imagem recuperada*/
      valPortadora[0] = valPortadora[0] &lt;&lt; (8-nbits);
      valPortadora[1] = valPortadora[1] &lt;&lt; (8-nbits);
      valPortadora[2] = valPortadora[2] &lt;&lt; (8-nbits);

      imagemFinal.at&lt;cv::Vec3b&gt;(i, j) = valPortadora;
    }
  }

  cv::imshow("Original", imagemPortadora);
  cv::waitKey();
  cv::imshow("Decodificada", imagemFinal);
  cv::waitKey();
  return 0;
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>A implementação foi testada com a imagem mostrada Figura abaixo.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="figuras/desafio-esteganografia.png" alt="desafio esteganografia" width="300" height="300">
</div>
<div class="title">Figure 6. Imagem codificada</div>
</div>
<div class="paragraph">
<p>Ao realizar a decodificação por meio deslocamento do pixels menos significativos da imagem original para o mais significativos da imagem final, foi obtido o resultado abaixo.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="figuras/decodifica.png" alt="decodifica" width="700" height="700">
</div>
<div class="title">Figure 7. Imagem decodificada</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_4_preenchendo_regiões">4 Preenchendo regiões</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_4_1_identificando_bolhas_com_ou_sem_buracos">4.1 Identificando bolhas com ou sem buracos</h3>
<div class="paragraph">
<p>Aprimorando o algoritmo <a href="https://agostinhobritojr.github.io/tutorial/pdi/exemplos/labeling.cpp">labeling.cpp</a>, o objetivo agora é identificar regiões com ou sem buracos internos que existam na imagem. Para isso, vamos assumir que objetos com mais de um buraco podem existir e que não devemos contar bolhas que tocam as bordas da imagem.</p>
</div>
<div class="paragraph">
<p>Abaixo temos o algoritmo completo que foi implementado.</p>
</div>
<div class="listingblock">
<div class="title">Código 6: buracosebolhas.cpp</div>
<div class="content">
<pre class="highlight"><code class="language-cpp" data-lang="cpp">#include &lt;iostream&gt;
#include &lt;opencv2/opencv.hpp&gt;

using namespace cv;

int main(int argc, char** argv) {
    cv::Mat image;
    int width, height;
    int total_bolhas=0;
    int bolhas_cm_buraco=0;
    int bolhas_na_borda=0;

    cv::Point p;
    image = cv::imread(argv[1], cv::IMREAD_GRAYSCALE);

    if (!image.data) {
        std::cout &lt;&lt; "imagem nao carregou corretamente\n";
        return (-1);
    }

    cv::imshow("Imagem original", image);
    cv::imwrite("original.png", image);
    cv::waitKey();

    width = image.cols;
    height = image.rows;
    std::cout &lt;&lt; width &lt;&lt; "x" &lt;&lt; height &lt;&lt; std::endl;

    p.x = 0;
    p.y = 0;

    /*
    Removendo bolhas das bordas:
    o loop verifica os bjetos presentes nas bordas
    e pinta de preto
    */
    for (int i = 0; i &lt; height; i++)
    {
        for (int j = 0; j &lt; width; j++)
        {
            if (i == 0 || i == (height - 1) || j == 0 || j == (width - 1))
            {
                if (image.at&lt;uchar&gt;(i, j) == 255)
                {
                    p.x = j;
                    p.y = i;
                    bolhas_na_borda++;
                    cv::floodFill(image, p, 0);
                }
            }
        }
    }

    cv::imshow("Sem bolhas na borda", image);
    cv::imwrite("borda.png", image);
    cv::waitKey();

    /*
    Contar bolhas com buraco: primeiro mudo a cor do fundo para
    um tom de cinza (100), assim só restará a cor preta dentro
    das bolhas com buraco permitindo a contagem.
    Depois o buraco é pintado de branco
    */
    p.x = 0;
    p.y = 0;
    cv::floodFill(image, p, 100);
    cv::imshow("Bolhas com buraco", image);
    cv::imwrite("buraco.png", image);
    cv::waitKey();

    for (int i = 0; i &lt; height; i++)
    {
        for (int j = 0; j &lt; width; j++)
        {
            if (image.at&lt;uchar&gt;(i, j) == 0)
            {
                p.x = j;
                p.y = i;
                bolhas_cm_buraco++;
                cv::floodFill(image, p, 255);
            }
        }
    }

    p.x = 0;
    p.y = 0;
    /*volta o fundo para a cor original (preto)*/
    cv::floodFill(image, p, 0);

    /*
    utilizando o algoritmo labeling conto o total de bolhas na imagem
    */

    for (int i = 0; i &lt; height; i++)
    {
        for (int j = 0; j &lt; width; j++)
        {
            if (image.at&lt;uchar&gt;(i, j) == 255)
            {
                // achou um objeto
                total_bolhas++;
                // para o floodfill as coordenadas
                // x e y são trocadas.
                p.x = j;
                p.y = i;
                // preenche o objeto com o contador
                cv::floodFill(image, p, total_bolhas);
            }
        }
    }

    int bolhas_sem_buraco=total_bolhas-bolhas_cm_buraco;

    cv::imshow("Bolhas", image);
    cv::imwrite("Bolhas.png", image);
    cv::waitKey();

    std::cout &lt;&lt; "Total de bolhas na imagem: " &lt;&lt; total_bolhas &lt;&lt; std:: endl;
    std::cout &lt;&lt; "Bolhas com buraco: " &lt;&lt; bolhas_cm_buraco &lt;&lt; std:: endl;
    std::cout &lt;&lt; "Bolhas sem buraco: " &lt;&lt; bolhas_sem_buraco &lt;&lt; std:: endl;
    std::cout &lt;&lt; "Bolhas que estavam na borda: " &lt;&lt; bolhas_na_borda &lt;&lt; std:: endl;

    return 0;
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>A cada mudança significativa foi gerada uma imagem. Assim, começamos mostrando como é a imagem original rotulada pelo programa.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="figuras/bolhas.png" alt="bolhas" width="300" height="300">
</div>
<div class="title">Figure 8. Imagem original bolhas.png</div>
</div>
<div class="paragraph">
<p>Com a retirada das bolhas contidas na borda da imagem, é gerada a segunda imagem:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="figuras/semborda.png" alt="semborda" width="300" height="300">
</div>
<div class="title">Figure 9. Imagem sem bolhas na borda</div>
</div>
<div class="paragraph">
<p>Para identificar quais bolhas possuíam buracos, a cor do fundo foi mudada de preto para um tom de cinza. Isso foi feito para que somente os buracos ficassem na cor preta, assim a imagem foi varrida e foi possível identificar a quantidade de bolhas com buraco.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="figuras/buracos.png" alt="buracos" width="300" height="300">
</div>
<div class="title">Figure 10. Bolhas com buraco</div>
</div>
<div class="paragraph">
<p>Em adição, os buracos foram removidos e a quantidade total de bolhas restantes foi contada. Além disso, o fundo voltou a ser preto permitindo que o labeling fosse  aplicado. A imagem final gerada pode ser vista abaixo:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="figuras/bolhaslab.png" alt="bolhaslab" width="300" height="300">
</div>
<div class="title">Figure 11. Resultado final do programa</div>
</div>
<div class="paragraph">
<p>No fim, o código exibe como resposta os seguintes dados:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>Total de bolhas na imagem: 21
Bolhas com buraco: 7
Bolhas sem buraco: 14
Bolhas que estavam na borda: 11</pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_5_manipulação_de_histogramas">5 Manipulação de histogramas</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_5_1_equalizar_imagem_cinza">5.1 Equalizar imagem cinza</h3>
<div class="paragraph">
<p>Utilizando o programa <a href="https://agostinhobritojr.github.io/tutorial/pdi/exemplos/histogram.cpp">histogram.cpp</a> como referência, foi implementado o programa equalize.cpp.</p>
</div>
<div class="paragraph">
<p>Este programa irá realizar a equalização do histograma de cada imagem capturada antes de exibí-la. O teste foi feito utilizando o vídeo paisagem,mp4.mp4 que exibe diversos ambientes com iluminações variadas.</p>
</div>
<div class="paragraph">
<p>Primeiramente é preciso que as imagens processadas estejam em tons de cinza, para isso foi utilizada a função <a href="https://docs.opencv.org/3.4/d8/d01/group__imgproc__color__conversions.html">cvtColor</a> do Opencv. Feito isso, o histograma da imagem é equalizado com a função <a href="https://docs.opencv.org/3.4/d4/d1b/tutorial_histogram_equalization.html">equalizeHist</a>. Com isso foi possível equalizar a imagem do vídeo utilizado.</p>
</div>
<div class="paragraph">
<p>O algoritmo completo pode ser visualizado abaixo.</p>
</div>
<div class="listingblock">
<div class="title">Código 7: equalize.cpp</div>
<div class="content">
<pre class="highlight"><code class="language-cpp" data-lang="cpp">#include &lt;iostream&gt;
#include &lt;opencv2/opencv.hpp&gt;

int main(int argc, char** argv){
  cv::Mat image, framequalizado;
  int width, height;
  cv::VideoCapture cap;
  std::vector&lt;cv::Mat&gt; planes;
  cv::Mat hist, historiginal;
  int nbins = 64;
  float range[] = {0, 255};
  const float *histrange = { range };
  bool uniform = true;
  bool acummulate = false;
  int key;

	cap.open("paisagem.mp4");

  if(!cap.isOpened()){
    std::cout &lt;&lt; "video indisponível";
    return -1;
  }

  cap.set(cv::CAP_PROP_FRAME_WIDTH, 640);
  cap.set(cv::CAP_PROP_FRAME_HEIGHT, 480);
  width = cap.get(cv::CAP_PROP_FRAME_WIDTH);
  height = cap.get(cv::CAP_PROP_FRAME_HEIGHT);

  std::cout &lt;&lt; "largura = " &lt;&lt; width &lt;&lt; std::endl;
  std::cout &lt;&lt; "altura  = " &lt;&lt; height &lt;&lt; std::endl;

  int histw = nbins, histh = nbins/2;
  cv::Mat hist1(histh, histw, CV_8UC1, cv::Scalar(0));
  cv::Mat hist2(histh, histw, CV_8UC1, cv::Scalar(0));

  while(1){
    cap &gt;&gt; image;

    /*converter frame colorido para cinza*/
    cv::cvtColor(image, image, cv::COLOR_BGR2GRAY);

    /*equalizar histograma com função do opencv*/
    cv::equalizeHist(image, framequalizado);

    /*Calcular o histograma das imagem original*/
    cv::calcHist(&amp;image, 1, 0, cv::Mat(), historiginal, 1, &amp;nbins, &amp;histrange, uniform, acummulate);

    /*Calcular o histograma das equalizada*/
    cv::calcHist(&amp;framequalizado, 1, 0, cv::Mat(), hist, 1, &amp;nbins, &amp;histrange, uniform, acummulate);

    /*normalizar os histogramas*/
    cv::normalize(historiginal, historiginal, 0, hist1.rows, cv::NORM_MINMAX, -1, cv::Mat());
    cv::normalize(hist, hist, 0, hist2.rows, cv::NORM_MINMAX, -1, cv::Mat());

    hist1.setTo(cv::Scalar(0));
    hist2.setTo(cv::Scalar(0));

    for(int i=0; i&lt;nbins; i++){
        cv::line(hist1,
               cv::Point(i, histh),
               cv::Point(i, histh-cvRound(historiginal.at&lt;float&gt;(i))),
               cv::Scalar(255, 255, 255), 1, 8, 0);
        cv::line(hist2,
               cv::Point(i, histh),
               cv::Point(i, histh-cvRound(hist.at&lt;float&gt;(i))),
               cv::Scalar(255, 255, 255), 1, 8, 0);
    }

    hist1.copyTo(image(cv::Rect(0,0,nbins, histh)));
    hist2.copyTo(framequalizado(cv::Rect(0,0,nbins, histh)));
    cv::imshow("Original", image);
    cv::imshow("Equalizado", framequalizado);
    key = cv::waitKey(30);
    if(key == 27) break;
  }
  return 0;
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Como resultado foram obtidas imagens com maior nitidez e detalhes quando comparadas com a imagem original. Além disso, o histograma de ambas as imagens são mostrados no canto da janela, o intuito é ilustrar a diferença causada pelo processamento da imagem.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="figuras/result.png" alt="result" width="700" height="700">
</div>
<div class="title">Figure 12. Resultado do algoritmo de equalização</div>
</div>
</div>
<div class="sect2">
<h3 id="_5_2_detecção_de_movimento">5.2 Detecção de movimento</h3>
<div class="paragraph">
<p>Utilizando o programa <a href="https://agostinhobritojr.github.io/tutorial/pdi/exemplos/histogram.cpp">histogram.cpp</a> como referência, foi implementado o programa motiondetector.cpp.</p>
</div>
<div class="paragraph">
<p>Este programa irá, continuamente, calcular o histograma da imagem e compará-lo com o último histograma calculado. Foi considerado apenas a cor vermelha nesse algoritmo. Quando a diferença entre os dois programas ultrapassar um limiar pré-estabelecido, uma mensagem de aviso é exibida.</p>
</div>
<div class="paragraph">
<p>Com o histograma atual e anterior de cada frame do video paisagem.mp4, a comparação é realizada pela função <a href="https://docs.opencv.org/2.4/modules/imgproc/doc/histograms.html?comparehist#comparehist">compareHist()</a>. Essa função irá retornar a resultante de algum método de comparação entre os dados dos histogramas. Aqui foi utilizado o método de correlação para a comparação.</p>
</div>
<div class="paragraph">
<p>Nesse método, quando duas imagens tem histogramas iguais o valor retornado é 1. Quando as imagens possuem histogramas diferentes, o valor retornado vai se aproximando de zero. Assim, foi considerado que um movimento é detectado quando o valor da comparação é menor do que 0,99.</p>
</div>
<div class="paragraph">
<p>O algoritmo completo pode ser visualizado abaixo.</p>
</div>
<div class="listingblock">
<div class="title">Código 8: motiondetector.cpp</div>
<div class="content">
<pre class="highlight"><code class="language-cpp" data-lang="cpp">#include &lt;iostream&gt;
#include &lt;opencv2/opencv.hpp&gt;
#include &lt;opencv2/imgproc.hpp&gt;

int main(int argc, char** argv){
  cv::Mat image;
  int width, height;
  cv::VideoCapture cap;
  std::vector&lt;cv::Mat&gt; planes;
  cv::Mat histatual, histanterior;
  int nbins = 64;
  float range[] = {0, 255};
  const float *histrange = { range };
  bool uniform = true;
  bool acummulate = false;
  int key;

	cap.open("paisagem.mp4");

  if(!cap.isOpened()){
    std::cout &lt;&lt; "video indisponível";
    return -1;
  }

  cap.set(cv::CAP_PROP_FRAME_WIDTH, 640);
  cap.set(cv::CAP_PROP_FRAME_HEIGHT, 480);
  width = cap.get(cv::CAP_PROP_FRAME_WIDTH);
  height = cap.get(cv::CAP_PROP_FRAME_HEIGHT);

  std::cout &lt;&lt; "largura = " &lt;&lt; width &lt;&lt; std::endl;
  std::cout &lt;&lt; "altura  = " &lt;&lt; height &lt;&lt; std::endl;

  int histw = nbins, histh = nbins/2;
  cv::Mat histImgR(histh, histw, CV_8UC3, cv::Scalar(0,0,0));

    cap &gt;&gt; image;

  /*o slit é usado para separar somente a cor de interesse do programa,
  que no caso é vermelho*/
  cv::split(image, planes);

  /*calculando histograma da imagem considerando a cor vermelha*/
  cv::calcHist(&amp;planes[0], 1, 0, cv::Mat(), histatual, 1,
           &amp;nbins, &amp;histrange,
           uniform, acummulate);

  /*normalizando histograma*/
  cv::normalize(histatual, histatual, 0, histImgR.rows, cv::NORM_MINMAX, -1, cv::Mat());

  while(1){
    /*o histograma anterior recebe o atual*/
    histatual.copyTo(histanterior);

    cap &gt;&gt; image;

    cv::split(image,planes);

    cv::calcHist(&amp;planes[0], 1, 0, cv::Mat(), histatual, 1, &amp;nbins, &amp;histrange, uniform, acummulate);

    cv::normalize(histatual, histatual, 0, histImgR.rows, cv::NORM_MINMAX, -1, cv::Mat());

    histImgR.setTo(cv::Scalar(0));

    double comp = cv::compareHist(histatual, histanterior, cv::HISTCMP_CORREL);

    /*definição do limiar que define o movimento*/
    if(comp &lt; 0.99){
      std::cout&lt;&lt; "Movimento detectado\n";
    }

    for(int i=0; i&lt;nbins; i++){
        cv::line(histImgR,
               cv::Point(i, histh),
               cv::Point(i, histh-cvRound(histatual.at&lt;float&gt;(i))),
               cv::Scalar(0, 0, 255), 1, 8, 0);
    }

    histImgR.copyTo(image(cv::Rect(0,0,nbins, histh)));
    cv::imshow("Detector de movimento", image);
    key = cv::waitKey(30);
    if(key == 27) break;
  }
  return 0;
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Como resultado temos no terminal o aviso de movimento toda vez que há uma mudança significativa no vídeo.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="figuras/movimento.png" alt="movimento" width="700" height="700">
</div>
<div class="title">Figure 13. Resultado do algoritmo de detecção de movimento</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_6_filtragem_no_domínio_espacial_i">6 Filtragem no domínio espacial I</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_6_1_laplaciano_do_gaussiano_de_um_vídeo">6.1 Laplaciano do gaussiano de um vídeo</h3>
<div class="paragraph">
<p>Utilizando o programa <a href="https://agostinhobritojr.github.io/tutorial/pdi/exemplos/filtroespacial.cpp">filtroespacial.cpp</a> como referência, foi implementado o programa laplgauss.cpp.</p>
</div>
<div class="paragraph">
<p>O programa acrescenta uma nova funcionalidade ao exemplo fornecido, permitindo que seja calculado o laplaciano do gaussiano das imagens capturadas.</p>
</div>
<div class="paragraph">
<p>Assim, primeiramente foi feita a máscara laplaciana do gaussiano que é obtida através de uma operação de convolução:</p>
</div>
<div class="stemblock">
<div class="content">
\$∇^2(G (x, y ) ∗ f(x, y ))\$
</div>
</div>
<div class="paragraph">
<p>Onde, f(x, y) é uma imagem suavizada por uma ffunção Gaussiana. Assim, com as devidas simplicações e rearranjos obtém-se:</p>
</div>
<div class="stemblock">
<div class="content">
\$∇^2G (x, y ) = − 1/(2πσ^4)(1 − (x^2 + y^2)/σ^2) e^
(− (x^2 + y^2)/ (2σ^2))\$
</div>
</div>
<div class="paragraph">
<p>O qual pode ser representado pela máscara com 5 × 5 pixels abaixo.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="figuras/mascara.png" alt="mascara" width="200" height="200">
</div>
<div class="title">Figure 14. Máscara laplaciano do gaussiano</div>
</div>
<div class="paragraph">
<p>Com essa máscara bastou apenas incluir no switch-case um caso em que para um dado comando ela fosse utilizada. Optou-se por escolher "x" como comando para acionar o filtro laplaciano do gaussiano. Abaixo há o algoritmo completo utilizado.</p>
</div>
<div class="listingblock">
<div class="title">Código 9: laplgauss.cpp</div>
<div class="content">
<pre class="highlight"><code class="language-cpp" data-lang="cpp">#include &lt;iostream&gt;
#include &lt;opencv2/opencv.hpp&gt;

void printmask(cv::Mat &amp;m) {
  for (int i = 0; i &lt; m.size().height; i++) {
    for (int j = 0; j &lt; m.size().width; j++) {
      std::cout &lt;&lt; m.at&lt;float&gt;(i, j) &lt;&lt; ",";
    }
    std::cout &lt;&lt; "\n";
  }
}

int main(int, char **) {
  cv::VideoCapture cap;
  float media[] = {0.1111, 0.1111, 0.1111, 0.1111, 0.1111,
                   0.1111, 0.1111, 0.1111, 0.1111};
  float gauss[] = {0.0625, 0.125,  0.0625, 0.125, 0.25,
                   0.125,  0.0625, 0.125,  0.0625};
  float horizontal[] = {-1, 0, 1, -2, 0, 2, -1, 0, 1};
  float vertical[] = {-1, -2, -1, 0, 0, 0, 1, 2, 1};
  float laplacian[] = {0, -1, 0, -1, 4, -1, 0, -1, 0};
  float boost[] = {0, -1, 0, -1, 5.2, -1, 0, -1, 0};
  float laplgauss [] ={0,0,-1,0,0,0,-1,-2,-1,0,-1,-2,16,-2,-1,
                      0,-1,-2,-1,0,0,0,-1,0,0};

  cv::Mat frame, framegray, frame32f, frameFiltered;
  cv::Mat mask(3, 3, CV_32F), mask_scale;
  cv::Mat result;
  double width, height;
  int absolut;
  char key;

  cap.open("paisagem.mp4");

  if (!cap.isOpened())  // check if we succeeded
    return -1;

  cap.set(cv::CAP_PROP_FRAME_WIDTH, 640);
  cap.set(cv::CAP_PROP_FRAME_HEIGHT, 480);
  width = cap.get(cv::CAP_PROP_FRAME_WIDTH);
  height = cap.get(cv::CAP_PROP_FRAME_HEIGHT);
  std::cout &lt;&lt; "largura=" &lt;&lt; width &lt;&lt; "\n";
  std::cout &lt;&lt; "altura =" &lt;&lt; height &lt;&lt; "\n";
  std::cout &lt;&lt; "fps    =" &lt;&lt; cap.get(cv::CAP_PROP_FPS) &lt;&lt; "\n";
  std::cout &lt;&lt; "format =" &lt;&lt; cap.get(cv::CAP_PROP_FORMAT) &lt;&lt; "\n";
  std::cout &lt;&lt; "\nPressione as teclas para ativar o filtro: \n"
          "a - calcular módulo\n"
          "m - média\n"
          "g - gauss\n"
          "h - horizontal\n"
          "v - vertical\n"
          "l - laplaciano\n"
          "b - boost\n"
          "x - laplaciano do gaussiano\n"
          "esc - encerrar\n";

  cv::namedWindow("filtroespacial", cv::WINDOW_NORMAL);
  cv::namedWindow("original", cv::WINDOW_NORMAL);

  mask = cv::Mat(3, 3, CV_32F, media);
  absolut = 1;  // calcs abs of the image

  for (;;) {
    cap &gt;&gt; frame;  // get a new frame from camera
    cv::cvtColor(frame, framegray, cv::COLOR_BGR2GRAY);
    cv::flip(framegray, framegray, 1);
    cv::imshow("original", framegray);
    framegray.convertTo(frame32f, CV_32F);
    cv::filter2D(frame32f, frameFiltered, frame32f.depth(), mask,
                 cv::Point(1, 1), 0);
    if (absolut) {
      frameFiltered = cv::abs(frameFiltered);
    }

    frameFiltered.convertTo(result, CV_8U);

    cv::imshow("filtroespacial", result);

    key = (char)cv::waitKey(10);
    if (key == 27) break;  // esc pressed!
    switch (key) {
      case 'a':
        absolut = !absolut;
        std::cout &lt;&lt; "\nBotão a pressionado \n";
        break;
      case 'm':
        mask = cv::Mat(3, 3, CV_32F, media);
        std::cout &lt;&lt; "\nBotão m pressionado \n";
        printmask(mask);
        break;
      case 'g':
        mask = cv::Mat(3, 3, CV_32F, gauss);
        std::cout &lt;&lt; "\nBotão g pressionado \n";
        printmask(mask);
        break;
      case 'h':
        mask = cv::Mat(3, 3, CV_32F, horizontal);
        std::cout &lt;&lt; "\nBotão h pressionado \n";
        printmask(mask);
        break;
      case 'v':
        mask = cv::Mat(3, 3, CV_32F, vertical);
        std::cout &lt;&lt; "\nBotão v pressionado \n";
        printmask(mask);
        break;
      case 'l':
        mask = cv::Mat(3, 3, CV_32F, laplacian);
        std::cout &lt;&lt; "\nBotão l pressionado \n";
        printmask(mask);
        break;
      case 'b':
        mask = cv::Mat(3, 3, CV_32F, boost);
        std::cout &lt;&lt; "\nBotão b pressionado \n";
        break;
        case 'x':
        mask = cv::Mat(5, 5, CV_32F, laplgauss);
        std::cout &lt;&lt; "\nBotão x pressionado \n";
        printmask(mask);
        break;
      default:
        break;
    }
  }
  return 0;
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Para testar o algortimo foi utilizado um vídeo (paisagem.mp4). Ao pressionar o comando de adicionar o filtro laplaciano do gaussiano temos como resultado o frame abaixo.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="figuras/laplgauss.png" alt="laplgauss" width="700" height="700">
</div>
<div class="title">Figure 15. Frame do vídeo com filtro laplaciano do gaussiano</div>
</div>
<div class="paragraph">
<p>Em contrapatirda ao utilizar apenas o filtro laplaciano o resultado é o mostrado abaixo.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="figuras/lap.png" alt="lap" width="700" height="700">
</div>
<div class="title">Figure 16. Frame do vídeo com filtro laplaciano</div>
</div>
<div class="paragraph">
<p>Dessa forma, observou-se que o filtro laplaciano do gaussiano destaca mais os contornos e evidencia maiores detalhes da imagem.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_7_filtragem_no_domínio_da_frequência">7 Filtragem no domínio da frequência</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_7_1_a_transformada_de_fourier">7.1 A Transformada de Fourier</h3>
<div class="paragraph">
<p>Utilizando os programa <a href="https://agostinhobritojr.github.io/tutorial/pdi/exemplos/dftimage.cpp">dftimage.cpp</a>, foi calculado o espectro de magnitude da imagem abaixo.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="figuras/senoide-256.png" alt="senoide 256" width="250" height="250">
</div>
<div class="title">Figure 17. Imagem da senoide gerada pelo programa filestorage.cpp</div>
</div>
<div class="paragraph">
<p>O algoritmo completo pode ser visualizado abaixo.</p>
</div>
<div class="listingblock">
<div class="title">Código 10: dftimage.cpp</div>
<div class="content">
<pre class="highlight"><code class="language-cpp" data-lang="cpp">#include &lt;iostream&gt;
#include &lt;vector&gt;
#include &lt;opencv2/opencv.hpp&gt;

void swapQuadrants(cv::Mat&amp; image) {
  cv::Mat tmp, A, B, C, D;

  // se a imagem tiver tamanho impar, recorta a regiao para o maior
  // tamanho par possivel (-2 = 1111...1110)
  image = image(cv::Rect(0, 0, image.cols &amp; -2, image.rows &amp; -2));

  int centerX = image.cols / 2;
  int centerY = image.rows / 2;

  // rearranja os quadrantes da transformada de Fourier de forma que
  // a origem fique no centro da imagem
  // A B   -&gt;  D C
  // C D       B A
  A = image(cv::Rect(0, 0, centerX, centerY));
  B = image(cv::Rect(centerX, 0, centerX, centerY));
  C = image(cv::Rect(0, centerY, centerX, centerY));
  D = image(cv::Rect(centerX, centerY, centerX, centerY));

  // swap quadrants (Top-Left with Bottom-Right)
  A.copyTo(tmp);
  D.copyTo(A);
  tmp.copyTo(D);

  // swap quadrant (Top-Right with Bottom-Left)
  C.copyTo(tmp);
  B.copyTo(C);
  tmp.copyTo(B);
}

int main(int argc, char** argv) {
  cv::Mat image, padded, complexImage;
  std::vector&lt;cv::Mat&gt; planos;

  image = imread(argv[1], cv::IMREAD_GRAYSCALE);
  if (image.empty()) {
    std::cout &lt;&lt; "Erro abrindo imagem" &lt;&lt; argv[1] &lt;&lt; std::endl;
    return EXIT_FAILURE;
  }

  // expande a imagem de entrada para o melhor tamanho no qual a DFT pode ser
  // executada, preenchendo com zeros a lateral inferior direita.
  int dft_M = cv::getOptimalDFTSize(image.rows);
  int dft_N = cv::getOptimalDFTSize(image.cols);
  cv::copyMakeBorder(image, padded, 0, dft_M - image.rows, 0, dft_N - image.cols, cv::BORDER_CONSTANT, cv::Scalar::all(0));

  // prepara a matriz complexa para ser preenchida
  // primeiro a parte real, contendo a imagem de entrada
  planos.push_back(cv::Mat_&lt;float&gt;(padded));
  // depois a parte imaginaria com valores nulos
  planos.push_back(cv::Mat::zeros(padded.size(), CV_32F));

  // combina os planos em uma unica estrutura de dados complexa
  cv::merge(planos, complexImage);

  // calcula a DFT
  cv::dft(complexImage, complexImage);
  swapQuadrants(complexImage);

  // planos[0] : Re(DFT(image)
  // planos[1] : Im(DFT(image)
  cv::split(complexImage, planos);

  // calcula o espectro de magnitude e de fase (em radianos)
  cv::Mat magn, fase;
  cv::cartToPolar(planos[0], planos[1], magn, fase, false);
  cv::normalize(fase, fase, 0, 1, cv::NORM_MINMAX);

  // caso deseje apenas o espectro de magnitude da DFT, use:
  cv::magnitude(planos[0], planos[1], magn);

  // some uma constante para evitar log(0)
  // log(1 + sqrt(Re(DFT(image))^2 + Im(DFT(image))^2))
  magn += cv::Scalar::all(1);

  // calcula o logaritmo da magnitude para exibir
  // com compressao de faixa dinamica
  log(magn, magn);
  cv::normalize(magn, magn, 0, 1, cv::NORM_MINMAX);

  // exibe as imagens processadas
  cv::imshow("Imagem", image);
  cv::imshow("Espectro de magnitude", magn);
  cv::imshow("Espectro de fase", fase);

  cv::waitKey();
  return EXIT_SUCCESS;
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Como resultado foi obtido o espectro de magnitude mostrado abaixo.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="figuras/magnitude.png" alt="magnitude" width="250" height="250">
</div>
<div class="title">Figure 18. Resultado do algortimo dftimage.cpp</div>
</div>
<div class="paragraph">
<p>Na figura resultante, a transformada de Fourier em duas dimensões é representada visualmente como a imagem, onde cada pixel na imagem da transformada de Fourier (TF) representa um valor de frequência espacial. A magnitude desse valor é codificada pela intensidade luminosa do pixel.</p>
</div>
<div class="paragraph">
<p>A luminosidade dos picos na imagem da TF reflete o contraste na imagem no domínio espacial. Assim, quanto mais brilhantes os picos na imagem da TF, maior o contraste na
imagem no espaço.</p>
</div>
</div>
<div class="sect2">
<h3 id="_7_2_filtro_homomórfico">7.2 Filtro homomórfico</h3>
<div class="paragraph">
<p>Utilizando o programa <a href="https://agostinhobritojr.github.io/tutorial/pdi/exemplos/dftfilter.cpp">dftfilter.cpp</a> como referência, foi implementado o filtro homomórfico para melhorar uma imagem, fornecida é em tons de cinza, com iluminação irregular.</p>
</div>
<div class="paragraph">
<p>Primeiramente é preciso entender que o Filtro Homomórfico atenua as baixas-frequências e realça as altas baseando-se no modelo de iluminação-refletância.</p>
</div>
<div class="paragraph">
<p>Para isso, utilizamos a seguinte equação:</p>
</div>
<div class="stemblock">
<div class="content">
\$H(u,v)= (\gamma H - \gamma L) (1- e^(-c*(D^2( u,v ))/D_0^2)) + \gamma L\$
</div>
</div>
<div class="paragraph">
<p>Onde, o parâmetro da iluminação (γL) é o componente de baixa frequência e o parâmetro da refletância é o de alta frequência (γH). Para aumentar o contraste da imagem a iluminação é diminuída (0 &lt; γL &lt; 1) e a refletância é aumentada (γH &gt; 1).</p>
</div>
<div class="paragraph">
<p>Assim, os parâmetros do filtro homomórfico foram ajustados para corrigir a iluminação da melhor forma possível.</p>
</div>
<div class="paragraph">
<p>O algoritmo completo pode ser visualizado abaixo.</p>
</div>
<div class="listingblock">
<div class="title">Código 11: dftfilterhomo.cpp</div>
<div class="content">
<pre class="highlight"><code class="language-cpp" data-lang="cpp">#include &lt;iostream&gt;
#include &lt;vector&gt;
#include &lt;math.h&gt;
#include &lt;opencv2/opencv.hpp&gt;

void swapQuadrants(cv::Mat&amp; image) {
  cv::Mat tmp, A, B, C, D;

  // se a imagem tiver tamanho impar, recorta a regiao para o maior
  // tamanho par possivel (-2 = 1111...1110)
  image = image(cv::Rect(0, 0, image.cols &amp; -2, image.rows &amp; -2));

  int centerX = image.cols / 2;
  int centerY = image.rows / 2;

  // rearranja os quadrantes da transformada de Fourier de forma que
  // a origem fique no centro da imagem
  // A B   -&gt;  D C
  // C D       B A
  A = image(cv::Rect(0, 0, centerX, centerY));
  B = image(cv::Rect(centerX, 0, centerX, centerY));
  C = image(cv::Rect(0, centerY, centerX, centerY));
  D = image(cv::Rect(centerX, centerY, centerX, centerY));

  // swap quadrants (Top-Left with Bottom-Right)
  A.copyTo(tmp);
  D.copyTo(A);
  tmp.copyTo(D);

  // swap quadrant (Top-Right with Bottom-Left)
  C.copyTo(tmp);
  B.copyTo(C);
  tmp.copyTo(B);
}

void makeFilter(const cv::Mat &amp;image, cv::Mat &amp;filter){
  cv::Mat_&lt;float&gt; filter2D(image.rows, image.cols);
  int centerX = image.cols / 2;
  int centerY = image.rows / 2;
  /* Aumenta-se o contraste da imagem ...*/
  float YH = 1.5; /*e a refletância é aumentada (γH &gt; 1)*/
  float YL = 0.25; /*se a iluminação é diminuída (0 &lt; γL &lt; 1)*/
  float c = 1.0;

  /* Para fazer o filtro homomórfico considera-se a seguinte equação:
     H(u,v) = (γH − γL)(1 − e^(− c(D²(u,v)/D0²))) + γL
  */

  for (int i = 0; i &lt; image.rows; i++){
    for (int j = 0; j &lt; image.cols; j++){
      float D = sqrt(pow(i-centerY,2) + pow(j-centerX,2));
      float H = (YH - YL) * (1.0 - exp(-c * (pow(D,2) / pow(centerX,2)))) + YL;
      filter2D.at&lt;float&gt;(i, j) = H;
    }
  }
  cv::Mat planes[] = {cv::Mat_&lt;float&gt;(filter2D), cv::Mat::zeros(filter2D.size(), CV_32F)};
  cv::merge(planes, 2, filter);
}

int main(int argc, char** argv) {
  cv::Mat image, padded, complexImage;
  std::vector&lt;cv::Mat&gt; planos;

  image = imread(argv[1], cv::IMREAD_GRAYSCALE);
  if (image.empty()) {
    std::cout &lt;&lt; "Erro abrindo imagem" &lt;&lt; argv[1] &lt;&lt; std::endl;
    return EXIT_FAILURE;
  }


  // expande a imagem de entrada para o melhor tamanho no qual a DFT pode ser
  // executada, preenchendo com zeros a lateral inferior direita.
  int dft_M = cv::getOptimalDFTSize(image.rows);
  int dft_N = cv::getOptimalDFTSize(image.cols);
  cv::copyMakeBorder(image, padded, 0, dft_M - image.rows, 0, dft_N - image.cols, cv::BORDER_CONSTANT, cv::Scalar::all(0));

  // prepara a matriz complexa para ser preenchida
  // primeiro a parte real, contendo a imagem de entrada
  planos.push_back(cv::Mat_&lt;float&gt;(padded));
  // depois a parte imaginaria com valores nulos
  planos.push_back(cv::Mat::zeros(padded.size(), CV_32F));

  // combina os planos em uma unica estrutura de dados complexa
  cv::merge(planos, complexImage);

  // calcula a DFT
  cv::dft(complexImage, complexImage);
  swapQuadrants(complexImage);

  // cria o filtro ideal e aplica a filtragem de frequencia
  cv::Mat filter;
  makeFilter(complexImage, filter);
  cv::mulSpectrums(complexImage, filter, complexImage, 0);

  // calcula a DFT inversa
  swapQuadrants(complexImage);
  cv::idft(complexImage, complexImage);

  // planos[0] : Re(DFT(image)
  // planos[1] : Im(DFT(image)
  cv::split(complexImage, planos);

  // recorta a imagem filtrada para o tamanho original
  // selecionando a regiao de interesse (roi)
  cv::Rect roi(0, 0, image.cols, image.rows);
  cv::Mat result = planos[0](roi);

  // normaliza a parte real para exibicao
  cv::normalize(result, result, 0, 1, cv::NORM_MINMAX);

  cv::imshow("original", image);
  cv::imshow("filtrada", result);
  cv::imwrite("dft-filter.png", result * 255);

  cv::waitKey();
  return EXIT_SUCCESS;
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>O código original do algoritmo, disponível em <a href="https://agostinhobritojr.github.io/tutorial/pdi/exemplos/dftfilter.cpp">dftfilter.cpp</a>, passou por modificações apenas na função "filter". Nessa função, a equação anterior foi substituída pela fórmula do filtro homomórfico.</p>
</div>
<div class="paragraph">
<p>A imagem utilizada para testes é apresentada abaixo, que possui uma iluminação mais intensa em torno da mulher, enquanto que o restante do cenário recebe pouca iluminação.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="figuras/img.png" alt="img" width="500" height="500">
</div>
<div class="title">Figure 19. Imagem com iluminação focada na mulher</div>
</div>
<div class="paragraph">
<p>Os valores de γL e γH foram ajustados para melhorar a distribuição da luz na imagem, resultando no que vemos na imagem apresentada abaixo. Observa-se uma distribuição mais uniforme da luminosidade em toda a imagem, indicando que houve uma melhoria no balanceamento da iluminação.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="figuras/dft-filter.png" alt="dft filter" width="500" height="500">
</div>
<div class="title">Figure 20. Imagem com iluminação focada na mulher</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_8_segmentação_de_imagens">8 Segmentação de imagens</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_8_1_pontilhismo_com_algoritmo_de_canny">8.1 Pontilhismo com algoritmo de Canny</h3>
<div class="paragraph">
<p>Utilizando os programas <a href="https://agostinhobritojr.github.io/tutorial/pdi/exemplos/esteg-encode.cpp">canny.cpp</a> e <a href="https://agostinhobritojr.github.io/tutorial/pdi/exemplos/canny.cpp">pontilhismo.cpp</a> como referência, foi implementado o programa cannypoints.cpp.</p>
</div>
<div class="paragraph">
<p>A ideia aqui é usar as bordas produzidas pelo algoritmo de Canny para melhorar a qualidade da imagem pontilhista gerada. Assim, foi feita uma alteração no laço de repetição do algoritmo de pontilhismo para que fossem consideradas as bordas detectadas pelo algoritmo de Canny.</p>
</div>
<div class="paragraph">
<p>Na posição dos pixels de borda, encontrados pelo algoritmo de Canny, o usuário poderá definir o raio dos pontos para gerar a imagem pontilhista. Esse raio será definido por uma trackbar, que é uma barra deslizante que permite escolher um valor para o raio indo de 0 a 10.</p>
</div>
<div class="paragraph">
<p>Nos demais pixels da imagem um raio fixo de tamanho 3 será aplicado.</p>
</div>
<div class="paragraph">
<p>O algoritmo completo pode ser visualizado abaixo.</p>
</div>
<div class="listingblock">
<div class="title">Código 12: cannypoints.cpp</div>
<div class="content">
<pre class="highlight"><code class="language-cpp" data-lang="cpp">#include &lt;algorithm&gt;
#include &lt;cstdlib&gt;
#include &lt;ctime&gt;
#include &lt;fstream&gt;
#include &lt;iomanip&gt;
#include &lt;iostream&gt;
#include &lt;numeric&gt;
#include &lt;opencv2/opencv.hpp&gt;
#include &lt;vector&gt;

int STEP = 5;
int JITTER = 3;
int RAIO = 3;
int top_slider = 10;
int top_slider_max = 200;

char TrackbarName[50];

cv::Mat image, border, points;

void pointillism (){

    std::vector&lt;int&gt; yrange;
    std::vector&lt;int&gt; xrange;
    cv::Vec3b color;

    int width, height;
    int x, y;

    width = image.cols;
    height = image.rows;

    xrange.resize(height / STEP);
    yrange.resize(width / STEP);

    std::iota(xrange.begin(), xrange.end(), 0);
    std::iota(yrange.begin(), yrange.end(), 0);

    for (uint i = 0; i &lt; xrange.size(); i++) {
        xrange[i] = xrange[i] * STEP + STEP / 2;
    }

    for (uint i = 0; i &lt; yrange.size(); i++) {
        yrange[i] = yrange[i] * STEP + STEP / 2;
    }

    points = cv::Mat(height, width, CV_8UC3, cv::Scalar(255, 255, 255)); // Imagem colorida

    std::random_shuffle(xrange.begin(), xrange.end());

    for (auto i : xrange) {

        std::random_shuffle(yrange.begin(), yrange.end());
        for (auto j : yrange) {

            if (border.at&lt;uchar&gt;(i, j) == 255){
                x = i+ std::rand()%(2*JITTER)-JITTER+1;
                y = j+ std::rand()%(2*JITTER)-JITTER+1;
                color = image.at&lt;cv::Vec3b&gt;(x,y);
                circle(points, cv::Point(y, x), RAIO, cv::Scalar(color[0], color[1], color[2]),
                cv::FILLED, cv::LINE_AA);
            }
            else{
                x = i+ std::rand()%(2*JITTER)-JITTER+1;
                y = j+ std::rand()%(2*JITTER)-JITTER+1;
                color = image.at&lt;cv::Vec3b&gt;(x,y);
                circle(points, cv::Point(y, x), 3, cv::Scalar(color[0], color[1], color[2]),
                cv::FILLED, cv::LINE_AA);
            }
        }
    }

}

void on_trackbar_canny(int, void*){
    cv::Canny(image, border, top_slider, 3*top_slider);
    cv::imshow("Canny", border);
}

void on_trackbar_canny_points(int,void*){
    pointillism();
    cv::imshow("Pontilhismo", points);

}

int main(int argc, char** argv) {

    image = cv::imread(argv[1],cv::IMREAD_COLOR);
    //int resize_scaling = 50;
    //float newWidth = image.size().width * resize_scaling/100;
    //float newHeight = image.size().height * resize_scaling/100;

    //cv::resize(image, image, cv::Size(newWidth, newHeight), cv::INTER_LINEAR);

    std::srand(std::time(0));

    if (image.empty()) {
        std::cout &lt;&lt; "Could not open or find the image" &lt;&lt; std::endl;
        return -1;
    }


    sprintf( TrackbarName, "Threshold inferior", top_slider_max );

    cv::namedWindow("Canny", 1);

    cv::createTrackbar(TrackbarName, "Canny",
                    &amp;top_slider,
                    top_slider_max,
                    on_trackbar_canny );

    on_trackbar_canny(top_slider, 0);

    // Pontilhismo
    sprintf(TrackbarName, "Raio");

    cv::namedWindow("Pontilhismo", 1);
    cv::createTrackbar(TrackbarName, "Pontilhismo",
                       &amp;RAIO,
                       10,
                       on_trackbar_canny_points);
    on_trackbar_canny_points(RAIO, 0);

    cv::waitKey();
    //cv::imwrite("borda.png", border);
    //cv::imwrite("pointilhismo.png", points);

    return 1;

}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Para testar o algortimo foi utilizado a imagem abaixo.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="figuras/mids.jpg" alt="mids" width="600" height="600">
</div>
<div class="title">Figure 21. Imagem retirada do filme Midsommar (2019)</div>
</div>
<div class="paragraph">
<p>Observe que quando o programa é executado, nas regiões da imagem em que não há bordas temos circulos pequeno (raio=3) e nas regiões com borda foi especificado que os círculos devem ter um raio de 5.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="figuras/resultado.png" alt="resultado" width="600" height="600">
</div>
<div class="title">Figure 22. Resultado do programa com raio 5</div>
</div>
<div class="paragraph">
<p>Aumentei o limiar no algoritmo de Canny para tornar mais visíveis os contornos nas flores. Além disso, aumentei o raio dos círculos para 8. Dessa forma, a distinção entre os pontos que não estão na borda de Canny (com raio 3) e aqueles na borda torna-se mais evidente.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="figuras/result_flowers.png" alt="result flowers" width="600" height="600">
</div>
<div class="title">Figure 23. Resultado do programa com raio 8</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_projeto_final">Projeto Final</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_detector_de_cor_de_uma_região_de_interesse_em_tempo_real">Detector de Cor de uma Região de Interesse em Tempo Real</h3>
<div class="paragraph">
<p>O projeto apresentado tem por objetivo criar um detector de cores utilizando processamento de imagem em tempo real. A implementação utiliza a biblioteca OpenCV em Python para capturar e analisar frames retirados de uma região de interesse (ROI) de uma webcam.</p>
</div>
<div class="paragraph">
<p>A detecção de cores é realizada no espaço de cores HSV (Matiz, Saturação, Valor). Esse modelo de representação de cores separa as informações em cor, intensidade e brilho, proporcionando uma maneira mais intuitiva de descrever e manipular cores em comparação com o modelo RGB (Vermelho, Verde, Azul).</p>
</div>
<div class="paragraph">
<p>De forma resumida, estes são os componentes do espaço de cores HSV:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>Matiz (H):
   O componente de matiz representa a tonalidade da cor. Ele descreve a cor pura em termos de sua posição angular ao redor do círculo de cores.</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>Saturação (S):
    A saturação refere-se à pureza ou intensidade da cor. Quanto maior a saturação, mais "pura" é a cor, e quanto menor, mais próxima do cinza.</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>Valor (V):
    O componente de valor indica a luminosidade ou brilho da cor. Ele determina a quantidade de luz presente na cor. Valores mais altos resultam em cores mais claras, enquanto valores mais baixos produzem cores mais escuras.</pre>
</div>
</div>
<div class="paragraph">
<p>O algoritmo realiza a média e o desvio padrão dos canais de cor na região escolhida, utilizando a biblioteca NumPy, como um mecanismo para ajustar a sensibilidade da detecção. Essa abordagem permite uma adaptação contínua às mudanças nas condições de iluminação e nas características específicas da cena em análise.</p>
</div>
<div class="paragraph">
<p>O cálculo da média dos canais de cor é para se obter uma representação central da cor predominante na região selecionada, enquanto o desvio padrão oferece uma medida da dispersão ou variabilidade dos tons presentes. Nesse contexto, subtraimos o desvio padrão da média no intuito de tornar a detecção mais específica, concentrando-se em tons de cor mais próximos à média.</p>
</div>
<div class="paragraph">
<p>Abaixo temos o código completo utilizado</p>
</div>
<div class="listingblock">
<div class="title">IdentificadorCor.py</div>
<div class="content">
<pre class="highlight"><code class="language-python" data-lang="python">import cv2
import numpy as np

retangulo = False
PosicaoROI = []

# função para escolher região em que a cor será detectada
def desenhar_retangulo(event, x, y, flags, param):
    global retangulo, PosicaoROI

    if event == cv2.EVENT_LBUTTONDOWN:
        retangulo = True
        PosicaoROI = [(x, y)]

    elif event == cv2.EVENT_LBUTTONUP:
        retangulo = False
        PosicaoROI.append((x, y))
        cv2.rectangle(frame, PosicaoROI[0], PosicaoROI[1], (0, 255, 0), 2)
        cv2.imshow('Webcam', frame)

# função para identificar a cor na região escolhida
def identificar_cor(roi):
    roi_hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)

    # calcule a média da cor na região HSV
    # a cor será um valor médio da região identificada

    media_cor = np.mean(roi_hsv, axis=(0, 1))
    desvio_cor = np.std(roi_hsv, axis=(0, 1))

    valorH, valorS, valorV = media_cor[0] - desvio_cor[0], media_cor[1] - desvio_cor[1], media_cor[2] - desvio_cor[2]

    if valorH &lt; 11:
        if valorV &lt; 50:
            return "Preto"
        elif valorS &lt; 50:
            return "Branco"
        else:
            return "Vermelho"
    elif valorH &lt; 22:
        if valorV&lt;50:
            return "Preto"
        elif valorS &lt; 50:
            return "Branco"
        else:
            return "Laranja"
    elif valorH &lt; 34:
        if valorV&lt;50:
            return "Preto"
        elif valorS &lt; 50:
            return "Branco"
        else:
            return "Amarelo"
    elif valorH &lt; 86:
        if valorV&lt;50:
            return "Preto"
        elif valorS &lt; 50:
            return "Branco"
        else:
            return "Verde"
    elif valorH &lt; 133:
        if valorV&lt;50:
            return "Preto"
        elif valorS &lt; 50:
            return "Branco"
        else:
            return "Azul"
    elif valorH &lt; 150:
        if valorV&lt;50:
            return "Preto"
        elif valorS &lt; 50:
            return "Branco"
        else:
            return "Violeta"
    elif valorH &lt; 170:
        if valorV&lt;50:
            return "Preto"
        elif valorS &lt; 50:
            return "Branco"
        else:
            return "Rosa"
    else:
        if valorV&lt;50:
            return "Preto"
        elif valorS &lt; 50:
            return "Branco"
        else:
            return "Vermelho"

#iniciar câmera
cap = cv2.VideoCapture(0)

#configura o callback do mouse
cv2.namedWindow('Webcam')
cv2.setMouseCallback('Webcam', desenhar_retangulo)

if not cap.isOpened():
    print("Câmera indisponível")
else:
    while True:
        ret, frame = cap.read()

        if len(PosicaoROI) == 2:
            roi = frame[PosicaoROI[0][1]:PosicaoROI[1][1], PosicaoROI[0][0]:PosicaoROI[1][0]]

            # realiza a detecção de cor na região de interesse (roi)
            cor = identificar_cor(roi)

            # escreve a cor identificada
            cv2.rectangle(frame, PosicaoROI[0], PosicaoROI[1], (0, 255, 0), 2)
            cv2.putText(frame, f'Cor: {cor}', (20, 60), 0, 0.7, (255, 255, 255), 2)

            # mostra a região de interesse de perto
            cv2.namedWindow('ROI')
            roi = cv2.resize(roi, (frame.shape[1], frame.shape[0]))
            cv2.resizeWindow('ROI', frame.shape[1], frame.shape[0])
            cv2.imshow('ROI', roi)


        cv2.imshow('Webcam', frame)
        key = cv2.waitKey(1)
        if key == 27: # se apertar esc fecha
            break

# liberar os recursos quando terminar
cap.release()
cv2.destroyAllWindows()</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Explicando o código</strong></p>
</div>
<div class="paragraph">
<p>Para começar, utiliza-se a biblioteca OpenCV para iniciar a captura de vídeo da webcam (cv2.VideoCapture) e configura-se um callback do mouse (cv2.setMouseCallback) para permitir a seleção da região de interesse (ROI) na imagem.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-python" data-lang="python"># Iniciar a câmera
cap = cv2.VideoCapture(0)

# Configurar o callback do mouse
cv2.namedWindow('Webcam')
cv2.setMouseCallback('Webcam', desenhar_retangulo)

# Verificar se a câmera está disponível
if not cap.isOpened():
    print("Câmera indisponível")
else:
    # ... Restante do código ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>A primeira função do programa é 'desenhar_retangulo', que é chamada sempre que ocorre um evento de clique do mouse. Então ao clicar no botão esquerdo do mouse, o usuário especifica as coordenadas (x, y) para iniciar o retângulo, e ao soltar o botão, as coordenadas correspondentes ao fim do retângulo são registradas. Essa função possibilita ao usuário desenhar um retângulo na tela, delimitando uma área específica de interesse.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-python" data-lang="python"># Função para escolher a região em que a cor será detectada
def desenhar_retangulo(event, x, y, flags, param):
    global retangulo, PosicaoROI

    if event == cv2.EVENT_LBUTTONDOWN:
        retangulo = True
        PosicaoROI = [(x, y)]

    elif event == cv2.EVENT_LBUTTONUP:
        retangulo = False
        PosicaoROI.append((x, y))
        cv2.rectangle(frame, PosicaoROI[0], PosicaoROI[1], (0, 255, 0), 2)
        cv2.imshow('Webcam', frame)</code></pre>
</div>
</div>
<div class="paragraph">
<p>Em seguida, temos a função 'identificar_cor' que recebe a região de interesse (ROI), já selecionada na função 'desenhar_retangulo', converte-a para o espaço de cores HSV e calcula a média e o desvio padrão dos canais de cor. Com base nesses valores, é determinada a cor predominante na região.</p>
</div>
<div class="paragraph">
<p>Optei por subtrair o desvio padrão da média para diminuir o intervalo de cores considerado na detecção. O objetivo foi tornar a detecção mais específica, concentrando-se em tons de cor mais próximos à média.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-python" data-lang="python"># Função para identificar a cor na região escolhida
def identificar_cor(roi):
    roi_hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)

    # Calcular a média e o desvio padrão da cor na região HSV
    media_cor = np.mean(roi_hsv, axis=(0, 1))
    desvio_cor = np.std(roi_hsv, axis=(0, 1))

    # Calcular os valores ajustados para sensibilidade
    valorH, valorS, valorV = media_cor[0] - desvio_cor[0], media_cor[1] - desvio_cor[1], media_cor[2] - desvio_cor[2]

    # Identificar a cor com base nos valores ajustados
    if valorH &lt; 11:
        # ... Restante do código ...
    # ... (Restante das condições de cor) ...
    else:
        # ... Restante do código ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Para visualização da região de interesse selecionada na tela da webcam inseri um retângulo verde. Adicionalmente, a cor identificada é exibida no canto superior esquerdo da janela principal. Além disso, uma visualização detalhada da região de interesse, ampliada, é apresentada em uma janela separada. Essa abordagem foi com o intuito de permitir uma visualização clara da região de interesse do usuário.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-python" data-lang="python"># mostrar a região de interesse
cv2.namedWindow('ROI')
roi = cv2.resize(roi, (frame.shape[1], frame.shape[0]))
cv2.resizeWindow('ROI', frame.shape[1], frame.shape[0])
cv2.imshow('ROI', roi)

# Mostrar a cor identificada na tela principal
cv2.rectangle(frame, PosicaoROI[0], PosicaoROI[1], (0, 255, 0), 2)
cv2.putText(frame, f'Cor: {cor}', (20, 60), 0, 0.7, (255, 255, 255), 2)</code></pre>
</div>
</div>
<div class="paragraph">
<p>Para mostrar o funcionamento do algoritmo, foi gravado um vídeo contendo objetos de diversas cores. Durante a análise, observou-se que ao identificar um objeto em condições de iluminação não uniforme, como o objeto amarelo do vídeo, o algoritmo apresenta algumas incertezas em relação à cor do objeto. Em determinadas situações, ocorre uma indecisão entre considerar o objeto como amarelo ou laranja, levando a resultados de cor variáveis para o mesmo objeto.</p>
</div>
<div class="paragraph">
<p>Essas pequenas limitações podem ser atribuídas ao fato de que a escolha da escala de cores HSV foi feita de forma empírica. Um refinamento mais preciso dessa escala pode ser necessário para lidar com variações sutis nas condições de iluminação.</p>
</div>
<div class="videoblock">
<div class="title">Teste do dectetor de cores</div>
<div class="content">
<video src="figuras/testpdi.mp4" controls>
Your browser does not support the video tag.
</video>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_referências">Referências</h3>
<div class="paragraph">
<p><a href="https://youtu.be/t71sQ6WY7L4">Simple Color recognition with Opencv and Python</a></p>
</div>
<div class="paragraph">
<p><a href="https://pyimagesearch.com/2015/03/09/capturing-mouse-click-events-with-python-and-opencv/">Capturing mouse click events with Python and OpenCV</a></p>
</div>
</div>
</div>
</div>
</div>
<div id="footer">
<div id="footer-text">
Last updated 2023-12-18 16:56:15 -0300
</div>
</div>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  messageStyle: "none",
  tex2jax: {
    inlineMath: [["\\(", "\\)"]],
    displayMath: [["\\[", "\\]"]],
    ignoreClass: "nostem|nolatexmath"
  },
  asciimath2jax: {
    delimiters: [["\\$", "\\$"]],
    ignoreClass: "nostem|noasciimath"
  },
  TeX: { equationNumbers: { autoNumber: "none" } }
})
MathJax.Hub.Register.StartupHook("AsciiMath Jax Ready", function () {
  MathJax.InputJax.AsciiMath.postfilterHooks.Add(function (data, node) {
    if ((node = data.script.parentNode) && (node = node.parentNode) && node.classList.contains('stemblock')) {
      data.math.root.display = "block"
    }
    return data
  })
})
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_HTMLorMML"></script>
</body>
</html>